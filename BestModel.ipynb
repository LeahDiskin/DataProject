{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of AnnaModel.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeahDiskin/DataProject/blob/main/BestModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "RyIoGuS2mtPS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "oEjRg8MXK76D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "from matplotlib import pyplot\n",
        "from keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import BatchNormalization\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "3Tlw2mYMjyYH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load train and test dataset\n",
        "def load_dataset():\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "LMGJrVhSAA5Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "UiUdnBuNAOdn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf725982-831e-4831-8d64-b41a1837afa2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "  \n",
        "loaded_data = np.load('/content/drive/MyDrive/Data Project/data.npz')\n",
        "x_train=loaded_data['x_train']\n",
        "x_validation=loaded_data['x_validation']\n",
        "x_test=loaded_data['x_test']\n",
        "y_train=loaded_data['y_train']\n",
        "y_test=loaded_data['y_test']\n",
        "y_validation=loaded_data['y_validation']\n",
        "num_classes =15\n",
        "# Convert class vectors to binary class matrices. This is called one hot encoding.\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "y_validation = to_categorical(y_validation)\n",
        " "
      ],
      "metadata": {
        "id": "f2Y-CUcQjwvi"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5udI56uYA85Y",
        "outputId": "3ab68093-ffea-4880-84d2-c7a1175d8836"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15000, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_validation = x_validation.astype('float32')\n",
        "\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "x_validation/=255\n",
        "\n"
      ],
      "metadata": {
        "id": "_WXPg2ybndE0"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def define_model():\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Dropout(0.2))\n",
        "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Dropout(0.3))\n",
        "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Dropout(0.4))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(Dropout(0.5))\n",
        "\tmodel.add(Dense(15, activation='softmax'))\n",
        "\t# compile model\n",
        "\topt = SGD(lr=0.001, momentum=0.9)\n",
        "\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\treturn model"
      ],
      "metadata": {
        "id": "VIlcg9jsnqF_"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_diagnostics(history):\n",
        "\t# plot loss\n",
        "\tpyplot.subplot(211)\n",
        "\tpyplot.title('Cross Entropy Loss')\n",
        "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
        "\t# plot accuracy\n",
        "\tpyplot.subplot(212)\n",
        "\tpyplot.title('Classification Accuracy')\n",
        "\tpyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
        "\t# save plot to file\n",
        "\tfilename = sys.argv[0].split('/')[-1]\n",
        "\tpyplot.savefig(filename + '_plot.png')\n"
      ],
      "metadata": {
        "id": "dp5pADQKnuXr"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load dataset\n",
        "# x_train,y_train,x_validation,y_validation,x_test,y_test = load_dataset()\n"
      ],
      "metadata": {
        "id": "88QAFqiOlysI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ceea094f-a4df-4355-bd87-21c6b8adbf54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare pixel data\n",
        "# x_train,y_train,x_validation,y_validation,x_test,y_test = prep_pixels(x_train,y_train,x_validation,y_validation,x_test,y_test)\n"
      ],
      "metadata": {
        "id": "FOa3OmF1ly4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define model\n",
        "model = define_model()\n"
      ],
      "metadata": {
        "id": "gE4Hv86zly6z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c190a8e9-2a37-4bad-ec20-3a2d0e153abc"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create data generator\n",
        "datagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n"
      ],
      "metadata": {
        "id": "I9YVc9dDly9m"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare iterator\n",
        "it_train = datagen.flow(x_train, y_train, batch_size=32)\n"
      ],
      "metadata": {
        "id": "VHP1Z8iRly_b"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit model\n",
        "steps = int(x_train.shape[0] / 32)\n",
        "history = model.fit_generator(it_train, steps_per_epoch=steps, epochs=250, validation_data=(x_validation,y_validation), verbose=1)\n"
      ],
      "metadata": {
        "id": "PeB2mSSalzBc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11121f60-87e7-41e1-9b81-7ef0d03114a1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/250\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1406/1406 [==============================] - 45s 23ms/step - loss: 2.4111 - accuracy: 0.2546 - val_loss: 1.7727 - val_accuracy: 0.4152\n",
            "Epoch 2/250\n",
            "1406/1406 [==============================] - 29s 20ms/step - loss: 1.9071 - accuracy: 0.3623 - val_loss: 1.6414 - val_accuracy: 0.4565\n",
            "Epoch 3/250\n",
            "1406/1406 [==============================] - 30s 21ms/step - loss: 1.7770 - accuracy: 0.4104 - val_loss: 1.6042 - val_accuracy: 0.4645\n",
            "Epoch 4/250\n",
            "1406/1406 [==============================] - 30s 21ms/step - loss: 1.6874 - accuracy: 0.4395 - val_loss: 1.5877 - val_accuracy: 0.4688\n",
            "Epoch 5/250\n",
            "1406/1406 [==============================] - 29s 21ms/step - loss: 1.6093 - accuracy: 0.4671 - val_loss: 1.4895 - val_accuracy: 0.5109\n",
            "Epoch 6/250\n",
            "1406/1406 [==============================] - 30s 21ms/step - loss: 1.5309 - accuracy: 0.4911 - val_loss: 1.3951 - val_accuracy: 0.5363\n",
            "Epoch 7/250\n",
            "1406/1406 [==============================] - 29s 21ms/step - loss: 1.4690 - accuracy: 0.5108 - val_loss: 1.3247 - val_accuracy: 0.5589\n",
            "Epoch 8/250\n",
            "1406/1406 [==============================] - 29s 21ms/step - loss: 1.4141 - accuracy: 0.5335 - val_loss: 1.2885 - val_accuracy: 0.5707\n",
            "Epoch 9/250\n",
            "1406/1406 [==============================] - 29s 21ms/step - loss: 1.3772 - accuracy: 0.5430 - val_loss: 1.2965 - val_accuracy: 0.5630\n",
            "Epoch 10/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 1.3395 - accuracy: 0.5568 - val_loss: 1.2379 - val_accuracy: 0.5865\n",
            "Epoch 11/250\n",
            "1406/1406 [==============================] - 29s 21ms/step - loss: 1.3016 - accuracy: 0.5704 - val_loss: 1.2019 - val_accuracy: 0.6007\n",
            "Epoch 12/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 1.2715 - accuracy: 0.5846 - val_loss: 1.2212 - val_accuracy: 0.5964\n",
            "Epoch 13/250\n",
            "1406/1406 [==============================] - 29s 21ms/step - loss: 1.2369 - accuracy: 0.5928 - val_loss: 1.1790 - val_accuracy: 0.6083\n",
            "Epoch 14/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 1.2153 - accuracy: 0.6010 - val_loss: 1.1269 - val_accuracy: 0.6283\n",
            "Epoch 15/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 1.1890 - accuracy: 0.6063 - val_loss: 1.2082 - val_accuracy: 0.6019\n",
            "Epoch 16/250\n",
            "1406/1406 [==============================] - 29s 21ms/step - loss: 1.1704 - accuracy: 0.6174 - val_loss: 1.1023 - val_accuracy: 0.6355\n",
            "Epoch 17/250\n",
            "1406/1406 [==============================] - 29s 20ms/step - loss: 1.1569 - accuracy: 0.6173 - val_loss: 1.0567 - val_accuracy: 0.6419\n",
            "Epoch 18/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 1.1333 - accuracy: 0.6298 - val_loss: 0.9513 - val_accuracy: 0.6832\n",
            "Epoch 19/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 1.1147 - accuracy: 0.6356 - val_loss: 1.1340 - val_accuracy: 0.6261\n",
            "Epoch 20/250\n",
            "1406/1406 [==============================] - 29s 21ms/step - loss: 1.0962 - accuracy: 0.6413 - val_loss: 0.9720 - val_accuracy: 0.6767\n",
            "Epoch 21/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 1.0748 - accuracy: 0.6454 - val_loss: 0.9640 - val_accuracy: 0.6790\n",
            "Epoch 22/250\n",
            "1406/1406 [==============================] - 29s 21ms/step - loss: 1.0623 - accuracy: 0.6526 - val_loss: 0.9291 - val_accuracy: 0.6905\n",
            "Epoch 23/250\n",
            "1406/1406 [==============================] - 29s 21ms/step - loss: 1.0541 - accuracy: 0.6548 - val_loss: 0.9563 - val_accuracy: 0.6816\n",
            "Epoch 24/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 1.0374 - accuracy: 0.6604 - val_loss: 0.8866 - val_accuracy: 0.7070\n",
            "Epoch 25/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 1.0250 - accuracy: 0.6648 - val_loss: 0.8343 - val_accuracy: 0.7199\n",
            "Epoch 26/250\n",
            "1406/1406 [==============================] - 29s 21ms/step - loss: 1.0094 - accuracy: 0.6713 - val_loss: 0.9003 - val_accuracy: 0.7039\n",
            "Epoch 27/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.9978 - accuracy: 0.6734 - val_loss: 0.8781 - val_accuracy: 0.7114\n",
            "Epoch 28/250\n",
            "1406/1406 [==============================] - 29s 21ms/step - loss: 0.9934 - accuracy: 0.6768 - val_loss: 0.8556 - val_accuracy: 0.7160\n",
            "Epoch 29/250\n",
            "1406/1406 [==============================] - 29s 21ms/step - loss: 0.9773 - accuracy: 0.6808 - val_loss: 0.8640 - val_accuracy: 0.7161\n",
            "Epoch 30/250\n",
            "1406/1406 [==============================] - 29s 21ms/step - loss: 0.9688 - accuracy: 0.6831 - val_loss: 0.8410 - val_accuracy: 0.7215\n",
            "Epoch 31/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.9547 - accuracy: 0.6878 - val_loss: 0.8120 - val_accuracy: 0.7333\n",
            "Epoch 32/250\n",
            "1406/1406 [==============================] - 29s 21ms/step - loss: 0.9503 - accuracy: 0.6920 - val_loss: 0.8091 - val_accuracy: 0.7324\n",
            "Epoch 33/250\n",
            "1406/1406 [==============================] - 29s 21ms/step - loss: 0.9437 - accuracy: 0.6920 - val_loss: 0.8199 - val_accuracy: 0.7299\n",
            "Epoch 34/250\n",
            "1406/1406 [==============================] - 29s 21ms/step - loss: 0.9362 - accuracy: 0.6965 - val_loss: 0.7703 - val_accuracy: 0.7452\n",
            "Epoch 35/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.9193 - accuracy: 0.6998 - val_loss: 0.7474 - val_accuracy: 0.7510\n",
            "Epoch 36/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.9148 - accuracy: 0.7026 - val_loss: 0.7465 - val_accuracy: 0.7538\n",
            "Epoch 37/250\n",
            "1406/1406 [==============================] - 30s 21ms/step - loss: 0.9058 - accuracy: 0.7058 - val_loss: 0.8142 - val_accuracy: 0.7345\n",
            "Epoch 38/250\n",
            "1406/1406 [==============================] - 29s 20ms/step - loss: 0.8993 - accuracy: 0.7091 - val_loss: 0.7302 - val_accuracy: 0.7595\n",
            "Epoch 39/250\n",
            "1406/1406 [==============================] - 30s 21ms/step - loss: 0.8987 - accuracy: 0.7074 - val_loss: 0.7534 - val_accuracy: 0.7503\n",
            "Epoch 40/250\n",
            "1406/1406 [==============================] - 30s 21ms/step - loss: 0.8855 - accuracy: 0.7137 - val_loss: 0.8305 - val_accuracy: 0.7314\n",
            "Epoch 41/250\n",
            "1406/1406 [==============================] - 29s 21ms/step - loss: 0.8766 - accuracy: 0.7145 - val_loss: 0.7455 - val_accuracy: 0.7543\n",
            "Epoch 42/250\n",
            "1406/1406 [==============================] - 29s 21ms/step - loss: 0.8754 - accuracy: 0.7181 - val_loss: 0.7529 - val_accuracy: 0.7537\n",
            "Epoch 43/250\n",
            "1406/1406 [==============================] - 29s 21ms/step - loss: 0.8675 - accuracy: 0.7182 - val_loss: 0.7427 - val_accuracy: 0.7555\n",
            "Epoch 44/250\n",
            "1406/1406 [==============================] - 29s 21ms/step - loss: 0.8548 - accuracy: 0.7209 - val_loss: 0.7138 - val_accuracy: 0.7661\n",
            "Epoch 45/250\n",
            "1406/1406 [==============================] - 29s 21ms/step - loss: 0.8515 - accuracy: 0.7228 - val_loss: 0.7183 - val_accuracy: 0.7631\n",
            "Epoch 46/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.8457 - accuracy: 0.7238 - val_loss: 0.7185 - val_accuracy: 0.7632\n",
            "Epoch 47/250\n",
            "1406/1406 [==============================] - 29s 21ms/step - loss: 0.8393 - accuracy: 0.7272 - val_loss: 0.8023 - val_accuracy: 0.7336\n",
            "Epoch 48/250\n",
            "1406/1406 [==============================] - 29s 21ms/step - loss: 0.8314 - accuracy: 0.7311 - val_loss: 0.7475 - val_accuracy: 0.7561\n",
            "Epoch 49/250\n",
            "1406/1406 [==============================] - 29s 21ms/step - loss: 0.8317 - accuracy: 0.7299 - val_loss: 0.6884 - val_accuracy: 0.7745\n",
            "Epoch 50/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.8188 - accuracy: 0.7338 - val_loss: 0.6723 - val_accuracy: 0.7814\n",
            "Epoch 51/250\n",
            "1406/1406 [==============================] - 29s 21ms/step - loss: 0.8177 - accuracy: 0.7355 - val_loss: 0.6979 - val_accuracy: 0.7709\n",
            "Epoch 52/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.8146 - accuracy: 0.7364 - val_loss: 0.7487 - val_accuracy: 0.7553\n",
            "Epoch 53/250\n",
            "1406/1406 [==============================] - 29s 20ms/step - loss: 0.8060 - accuracy: 0.7397 - val_loss: 0.7194 - val_accuracy: 0.7656\n",
            "Epoch 54/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.7947 - accuracy: 0.7423 - val_loss: 0.6696 - val_accuracy: 0.7822\n",
            "Epoch 55/250\n",
            "1406/1406 [==============================] - 29s 20ms/step - loss: 0.7951 - accuracy: 0.7417 - val_loss: 0.7526 - val_accuracy: 0.7541\n",
            "Epoch 56/250\n",
            "1406/1406 [==============================] - 29s 20ms/step - loss: 0.7926 - accuracy: 0.7430 - val_loss: 0.7035 - val_accuracy: 0.7699\n",
            "Epoch 57/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.7837 - accuracy: 0.7454 - val_loss: 0.7982 - val_accuracy: 0.7429\n",
            "Epoch 58/250\n",
            "1406/1406 [==============================] - 29s 21ms/step - loss: 0.7835 - accuracy: 0.7451 - val_loss: 0.7093 - val_accuracy: 0.7643\n",
            "Epoch 59/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.7829 - accuracy: 0.7461 - val_loss: 0.6543 - val_accuracy: 0.7840\n",
            "Epoch 60/250\n",
            "1406/1406 [==============================] - 29s 21ms/step - loss: 0.7700 - accuracy: 0.7509 - val_loss: 0.6308 - val_accuracy: 0.7933\n",
            "Epoch 61/250\n",
            "1406/1406 [==============================] - 29s 20ms/step - loss: 0.7669 - accuracy: 0.7500 - val_loss: 0.7264 - val_accuracy: 0.7631\n",
            "Epoch 62/250\n",
            "1406/1406 [==============================] - 30s 21ms/step - loss: 0.7687 - accuracy: 0.7496 - val_loss: 0.6562 - val_accuracy: 0.7842\n",
            "Epoch 63/250\n",
            "1406/1406 [==============================] - 30s 21ms/step - loss: 0.7596 - accuracy: 0.7523 - val_loss: 0.6505 - val_accuracy: 0.7893\n",
            "Epoch 64/250\n",
            "1406/1406 [==============================] - 30s 21ms/step - loss: 0.7577 - accuracy: 0.7559 - val_loss: 0.6222 - val_accuracy: 0.7940\n",
            "Epoch 65/250\n",
            "1406/1406 [==============================] - 29s 20ms/step - loss: 0.7478 - accuracy: 0.7570 - val_loss: 0.6180 - val_accuracy: 0.8003\n",
            "Epoch 66/250\n",
            "1406/1406 [==============================] - 29s 20ms/step - loss: 0.7503 - accuracy: 0.7555 - val_loss: 0.6501 - val_accuracy: 0.7863\n",
            "Epoch 67/250\n",
            "1406/1406 [==============================] - 30s 21ms/step - loss: 0.7405 - accuracy: 0.7608 - val_loss: 0.6341 - val_accuracy: 0.7927\n",
            "Epoch 68/250\n",
            "1406/1406 [==============================] - 30s 21ms/step - loss: 0.7419 - accuracy: 0.7607 - val_loss: 0.6569 - val_accuracy: 0.7857\n",
            "Epoch 69/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.7350 - accuracy: 0.7635 - val_loss: 0.6353 - val_accuracy: 0.7941\n",
            "Epoch 70/250\n",
            "1406/1406 [==============================] - 30s 21ms/step - loss: 0.7372 - accuracy: 0.7629 - val_loss: 0.6381 - val_accuracy: 0.7928\n",
            "Epoch 71/250\n",
            "1406/1406 [==============================] - 29s 20ms/step - loss: 0.7240 - accuracy: 0.7615 - val_loss: 0.6647 - val_accuracy: 0.7838\n",
            "Epoch 72/250\n",
            "1406/1406 [==============================] - 30s 21ms/step - loss: 0.7213 - accuracy: 0.7663 - val_loss: 0.6159 - val_accuracy: 0.7986\n",
            "Epoch 73/250\n",
            "1406/1406 [==============================] - 30s 21ms/step - loss: 0.7254 - accuracy: 0.7640 - val_loss: 0.6429 - val_accuracy: 0.7899\n",
            "Epoch 74/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.7162 - accuracy: 0.7677 - val_loss: 0.5978 - val_accuracy: 0.8083\n",
            "Epoch 75/250\n",
            "1406/1406 [==============================] - 29s 20ms/step - loss: 0.7102 - accuracy: 0.7706 - val_loss: 0.6087 - val_accuracy: 0.8023\n",
            "Epoch 76/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.7205 - accuracy: 0.7666 - val_loss: 0.5853 - val_accuracy: 0.8105\n",
            "Epoch 77/250\n",
            "1406/1406 [==============================] - 29s 21ms/step - loss: 0.7073 - accuracy: 0.7713 - val_loss: 0.6165 - val_accuracy: 0.7970\n",
            "Epoch 78/250\n",
            "1406/1406 [==============================] - 29s 21ms/step - loss: 0.7100 - accuracy: 0.7698 - val_loss: 0.6065 - val_accuracy: 0.8014\n",
            "Epoch 79/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.7004 - accuracy: 0.7738 - val_loss: 0.6111 - val_accuracy: 0.8001\n",
            "Epoch 80/250\n",
            "1406/1406 [==============================] - 29s 21ms/step - loss: 0.6931 - accuracy: 0.7746 - val_loss: 0.6649 - val_accuracy: 0.7830\n",
            "Epoch 81/250\n",
            "1406/1406 [==============================] - 29s 21ms/step - loss: 0.6982 - accuracy: 0.7734 - val_loss: 0.6401 - val_accuracy: 0.7915\n",
            "Epoch 82/250\n",
            "1406/1406 [==============================] - 30s 21ms/step - loss: 0.6914 - accuracy: 0.7754 - val_loss: 0.5660 - val_accuracy: 0.8135\n",
            "Epoch 83/250\n",
            "1406/1406 [==============================] - 30s 21ms/step - loss: 0.6910 - accuracy: 0.7759 - val_loss: 0.6187 - val_accuracy: 0.7987\n",
            "Epoch 84/250\n",
            "1406/1406 [==============================] - 29s 20ms/step - loss: 0.6872 - accuracy: 0.7779 - val_loss: 0.6149 - val_accuracy: 0.7977\n",
            "Epoch 85/250\n",
            "1406/1406 [==============================] - 29s 20ms/step - loss: 0.6860 - accuracy: 0.7790 - val_loss: 0.5584 - val_accuracy: 0.8200\n",
            "Epoch 86/250\n",
            "1406/1406 [==============================] - 30s 21ms/step - loss: 0.6823 - accuracy: 0.7799 - val_loss: 0.6197 - val_accuracy: 0.7987\n",
            "Epoch 87/250\n",
            "1406/1406 [==============================] - 29s 20ms/step - loss: 0.6733 - accuracy: 0.7811 - val_loss: 0.6134 - val_accuracy: 0.7989\n",
            "Epoch 88/250\n",
            "1406/1406 [==============================] - 30s 21ms/step - loss: 0.6688 - accuracy: 0.7836 - val_loss: 0.5753 - val_accuracy: 0.8129\n",
            "Epoch 89/250\n",
            "1406/1406 [==============================] - 29s 21ms/step - loss: 0.6735 - accuracy: 0.7811 - val_loss: 0.6003 - val_accuracy: 0.8073\n",
            "Epoch 90/250\n",
            "1406/1406 [==============================] - 29s 21ms/step - loss: 0.6759 - accuracy: 0.7808 - val_loss: 0.5656 - val_accuracy: 0.8173\n",
            "Epoch 91/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.6620 - accuracy: 0.7852 - val_loss: 0.5741 - val_accuracy: 0.8120\n",
            "Epoch 92/250\n",
            "1406/1406 [==============================] - 30s 21ms/step - loss: 0.6679 - accuracy: 0.7824 - val_loss: 0.5704 - val_accuracy: 0.8154\n",
            "Epoch 93/250\n",
            "1406/1406 [==============================] - 29s 20ms/step - loss: 0.6579 - accuracy: 0.7861 - val_loss: 0.5890 - val_accuracy: 0.8075\n",
            "Epoch 94/250\n",
            "1406/1406 [==============================] - 30s 21ms/step - loss: 0.6652 - accuracy: 0.7847 - val_loss: 0.5684 - val_accuracy: 0.8139\n",
            "Epoch 95/250\n",
            "1406/1406 [==============================] - 29s 21ms/step - loss: 0.6555 - accuracy: 0.7865 - val_loss: 0.5923 - val_accuracy: 0.8075\n",
            "Epoch 96/250\n",
            "1406/1406 [==============================] - 30s 21ms/step - loss: 0.6482 - accuracy: 0.7888 - val_loss: 0.5542 - val_accuracy: 0.8185\n",
            "Epoch 97/250\n",
            "1406/1406 [==============================] - 29s 20ms/step - loss: 0.6498 - accuracy: 0.7872 - val_loss: 0.5951 - val_accuracy: 0.8068\n",
            "Epoch 98/250\n",
            "1406/1406 [==============================] - 29s 20ms/step - loss: 0.6463 - accuracy: 0.7918 - val_loss: 0.5706 - val_accuracy: 0.8159\n",
            "Epoch 99/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.6447 - accuracy: 0.7922 - val_loss: 0.5391 - val_accuracy: 0.8275\n",
            "Epoch 100/250\n",
            "1406/1406 [==============================] - 30s 21ms/step - loss: 0.6436 - accuracy: 0.7897 - val_loss: 0.5652 - val_accuracy: 0.8161\n",
            "Epoch 101/250\n",
            "1406/1406 [==============================] - 30s 21ms/step - loss: 0.6426 - accuracy: 0.7911 - val_loss: 0.5864 - val_accuracy: 0.8085\n",
            "Epoch 102/250\n",
            "1406/1406 [==============================] - 29s 21ms/step - loss: 0.6383 - accuracy: 0.7910 - val_loss: 0.5399 - val_accuracy: 0.8236\n",
            "Epoch 103/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.6312 - accuracy: 0.7973 - val_loss: 0.5422 - val_accuracy: 0.8231\n",
            "Epoch 104/250\n",
            "1406/1406 [==============================] - 29s 21ms/step - loss: 0.6323 - accuracy: 0.7954 - val_loss: 0.5822 - val_accuracy: 0.8098\n",
            "Epoch 105/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.6328 - accuracy: 0.7950 - val_loss: 0.5821 - val_accuracy: 0.8091\n",
            "Epoch 106/250\n",
            "1406/1406 [==============================] - 29s 20ms/step - loss: 0.6373 - accuracy: 0.7917 - val_loss: 0.5786 - val_accuracy: 0.8112\n",
            "Epoch 107/250\n",
            "1406/1406 [==============================] - 29s 21ms/step - loss: 0.6252 - accuracy: 0.7967 - val_loss: 0.5345 - val_accuracy: 0.8257\n",
            "Epoch 108/250\n",
            "1406/1406 [==============================] - 29s 20ms/step - loss: 0.6214 - accuracy: 0.7979 - val_loss: 0.5489 - val_accuracy: 0.8223\n",
            "Epoch 109/250\n",
            "1406/1406 [==============================] - 30s 21ms/step - loss: 0.6181 - accuracy: 0.8009 - val_loss: 0.5477 - val_accuracy: 0.8237\n",
            "Epoch 110/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.6245 - accuracy: 0.7962 - val_loss: 0.5567 - val_accuracy: 0.8210\n",
            "Epoch 111/250\n",
            "1406/1406 [==============================] - 30s 21ms/step - loss: 0.6206 - accuracy: 0.7974 - val_loss: 0.5919 - val_accuracy: 0.8111\n",
            "Epoch 112/250\n",
            "1406/1406 [==============================] - 30s 21ms/step - loss: 0.6127 - accuracy: 0.8001 - val_loss: 0.5617 - val_accuracy: 0.8189\n",
            "Epoch 113/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.6189 - accuracy: 0.7986 - val_loss: 0.5466 - val_accuracy: 0.8221\n",
            "Epoch 114/250\n",
            "1406/1406 [==============================] - 29s 20ms/step - loss: 0.6054 - accuracy: 0.8034 - val_loss: 0.5680 - val_accuracy: 0.8191\n",
            "Epoch 115/250\n",
            "1406/1406 [==============================] - 30s 21ms/step - loss: 0.6119 - accuracy: 0.8004 - val_loss: 0.5324 - val_accuracy: 0.8292\n",
            "Epoch 116/250\n",
            "1406/1406 [==============================] - 30s 21ms/step - loss: 0.6147 - accuracy: 0.7998 - val_loss: 0.5415 - val_accuracy: 0.8253\n",
            "Epoch 117/250\n",
            "1406/1406 [==============================] - 30s 21ms/step - loss: 0.6052 - accuracy: 0.8041 - val_loss: 0.5320 - val_accuracy: 0.8295\n",
            "Epoch 118/250\n",
            "1406/1406 [==============================] - 29s 20ms/step - loss: 0.6035 - accuracy: 0.8029 - val_loss: 0.5402 - val_accuracy: 0.8234\n",
            "Epoch 119/250\n",
            "1406/1406 [==============================] - 29s 20ms/step - loss: 0.6027 - accuracy: 0.8033 - val_loss: 0.5676 - val_accuracy: 0.8183\n",
            "Epoch 120/250\n",
            "1406/1406 [==============================] - 30s 21ms/step - loss: 0.5979 - accuracy: 0.8049 - val_loss: 0.5209 - val_accuracy: 0.8323\n",
            "Epoch 121/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.6009 - accuracy: 0.8042 - val_loss: 0.5573 - val_accuracy: 0.8213\n",
            "Epoch 122/250\n",
            "1406/1406 [==============================] - 30s 21ms/step - loss: 0.6000 - accuracy: 0.8034 - val_loss: 0.6079 - val_accuracy: 0.8023\n",
            "Epoch 123/250\n",
            "1406/1406 [==============================] - 30s 21ms/step - loss: 0.5970 - accuracy: 0.8058 - val_loss: 0.5533 - val_accuracy: 0.8228\n",
            "Epoch 124/250\n",
            "1406/1406 [==============================] - 29s 20ms/step - loss: 0.6015 - accuracy: 0.8052 - val_loss: 0.5390 - val_accuracy: 0.8282\n",
            "Epoch 125/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.5965 - accuracy: 0.8057 - val_loss: 0.5329 - val_accuracy: 0.8281\n",
            "Epoch 126/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.5996 - accuracy: 0.8053 - val_loss: 0.5076 - val_accuracy: 0.8362\n",
            "Epoch 127/250\n",
            "1406/1406 [==============================] - 29s 21ms/step - loss: 0.5939 - accuracy: 0.8065 - val_loss: 0.5142 - val_accuracy: 0.8332\n",
            "Epoch 128/250\n",
            "1406/1406 [==============================] - 30s 21ms/step - loss: 0.5867 - accuracy: 0.8074 - val_loss: 0.5041 - val_accuracy: 0.8371\n",
            "Epoch 129/250\n",
            "1406/1406 [==============================] - 29s 20ms/step - loss: 0.5889 - accuracy: 0.8072 - val_loss: 0.5334 - val_accuracy: 0.8309\n",
            "Epoch 130/250\n",
            "1406/1406 [==============================] - 30s 21ms/step - loss: 0.5882 - accuracy: 0.8100 - val_loss: 0.5154 - val_accuracy: 0.8348\n",
            "Epoch 131/250\n",
            "1406/1406 [==============================] - 29s 20ms/step - loss: 0.5837 - accuracy: 0.8111 - val_loss: 0.5585 - val_accuracy: 0.8197\n",
            "Epoch 132/250\n",
            "1406/1406 [==============================] - 29s 21ms/step - loss: 0.5829 - accuracy: 0.8105 - val_loss: 0.5175 - val_accuracy: 0.8345\n",
            "Epoch 133/250\n",
            "1406/1406 [==============================] - 29s 20ms/step - loss: 0.5774 - accuracy: 0.8119 - val_loss: 0.5098 - val_accuracy: 0.8375\n",
            "Epoch 134/250\n",
            "1406/1406 [==============================] - 29s 21ms/step - loss: 0.5789 - accuracy: 0.8121 - val_loss: 0.5278 - val_accuracy: 0.8303\n",
            "Epoch 135/250\n",
            "1406/1406 [==============================] - 29s 21ms/step - loss: 0.5817 - accuracy: 0.8111 - val_loss: 0.5062 - val_accuracy: 0.8372\n",
            "Epoch 136/250\n",
            "1406/1406 [==============================] - 29s 21ms/step - loss: 0.5828 - accuracy: 0.8111 - val_loss: 0.5092 - val_accuracy: 0.8381\n",
            "Epoch 137/250\n",
            "1406/1406 [==============================] - 29s 21ms/step - loss: 0.5744 - accuracy: 0.8139 - val_loss: 0.5336 - val_accuracy: 0.8316\n",
            "Epoch 138/250\n",
            "1406/1406 [==============================] - 30s 21ms/step - loss: 0.5681 - accuracy: 0.8144 - val_loss: 0.5142 - val_accuracy: 0.8333\n",
            "Epoch 139/250\n",
            "1406/1406 [==============================] - 31s 22ms/step - loss: 0.5691 - accuracy: 0.8148 - val_loss: 0.5161 - val_accuracy: 0.8335\n",
            "Epoch 140/250\n",
            "1406/1406 [==============================] - 31s 22ms/step - loss: 0.5688 - accuracy: 0.8141 - val_loss: 0.5508 - val_accuracy: 0.8231\n",
            "Epoch 141/250\n",
            "1406/1406 [==============================] - 30s 21ms/step - loss: 0.5623 - accuracy: 0.8148 - val_loss: 0.5187 - val_accuracy: 0.8342\n",
            "Epoch 142/250\n",
            "1406/1406 [==============================] - 30s 22ms/step - loss: 0.5632 - accuracy: 0.8163 - val_loss: 0.5138 - val_accuracy: 0.8365\n",
            "Epoch 143/250\n",
            "1406/1406 [==============================] - 30s 21ms/step - loss: 0.5658 - accuracy: 0.8136 - val_loss: 0.5053 - val_accuracy: 0.8377\n",
            "Epoch 144/250\n",
            "1406/1406 [==============================] - 30s 22ms/step - loss: 0.5635 - accuracy: 0.8168 - val_loss: 0.4867 - val_accuracy: 0.8426\n",
            "Epoch 145/250\n",
            "1406/1406 [==============================] - 29s 21ms/step - loss: 0.5686 - accuracy: 0.8155 - val_loss: 0.5260 - val_accuracy: 0.8313\n",
            "Epoch 146/250\n",
            "1406/1406 [==============================] - 29s 21ms/step - loss: 0.5520 - accuracy: 0.8206 - val_loss: 0.5307 - val_accuracy: 0.8301\n",
            "Epoch 147/250\n",
            "1406/1406 [==============================] - 30s 21ms/step - loss: 0.5585 - accuracy: 0.8181 - val_loss: 0.5164 - val_accuracy: 0.8340\n",
            "Epoch 148/250\n",
            "1406/1406 [==============================] - 29s 21ms/step - loss: 0.5575 - accuracy: 0.8186 - val_loss: 0.5739 - val_accuracy: 0.8180\n",
            "Epoch 149/250\n",
            "1406/1406 [==============================] - 31s 22ms/step - loss: 0.5583 - accuracy: 0.8184 - val_loss: 0.4786 - val_accuracy: 0.8457\n",
            "Epoch 150/250\n",
            "1406/1406 [==============================] - 31s 22ms/step - loss: 0.5576 - accuracy: 0.8174 - val_loss: 0.5187 - val_accuracy: 0.8332\n",
            "Epoch 151/250\n",
            "1406/1406 [==============================] - 30s 21ms/step - loss: 0.5557 - accuracy: 0.8192 - val_loss: 0.5208 - val_accuracy: 0.8339\n",
            "Epoch 152/250\n",
            "1406/1406 [==============================] - 31s 22ms/step - loss: 0.5603 - accuracy: 0.8175 - val_loss: 0.4890 - val_accuracy: 0.8423\n",
            "Epoch 153/250\n",
            "1406/1406 [==============================] - 30s 21ms/step - loss: 0.5479 - accuracy: 0.8206 - val_loss: 0.5100 - val_accuracy: 0.8375\n",
            "Epoch 154/250\n",
            "1406/1406 [==============================] - 31s 22ms/step - loss: 0.5512 - accuracy: 0.8192 - val_loss: 0.5131 - val_accuracy: 0.8375\n",
            "Epoch 155/250\n",
            "1406/1406 [==============================] - 30s 21ms/step - loss: 0.5502 - accuracy: 0.8217 - val_loss: 0.5314 - val_accuracy: 0.8297\n",
            "Epoch 156/250\n",
            "1406/1406 [==============================] - 29s 21ms/step - loss: 0.5564 - accuracy: 0.8205 - val_loss: 0.5197 - val_accuracy: 0.8339\n",
            "Epoch 157/250\n",
            "1406/1406 [==============================] - 31s 22ms/step - loss: 0.5489 - accuracy: 0.8214 - val_loss: 0.4867 - val_accuracy: 0.8435\n",
            "Epoch 158/250\n",
            "1406/1406 [==============================] - 30s 21ms/step - loss: 0.5480 - accuracy: 0.8221 - val_loss: 0.4915 - val_accuracy: 0.8432\n",
            "Epoch 159/250\n",
            "1406/1406 [==============================] - 30s 21ms/step - loss: 0.5506 - accuracy: 0.8192 - val_loss: 0.5230 - val_accuracy: 0.8317\n",
            "Epoch 160/250\n",
            "1406/1406 [==============================] - 31s 22ms/step - loss: 0.5411 - accuracy: 0.8244 - val_loss: 0.5034 - val_accuracy: 0.8375\n",
            "Epoch 161/250\n",
            "1406/1406 [==============================] - 30s 21ms/step - loss: 0.5334 - accuracy: 0.8255 - val_loss: 0.4888 - val_accuracy: 0.8441\n",
            "Epoch 162/250\n",
            "1406/1406 [==============================] - 30s 21ms/step - loss: 0.5387 - accuracy: 0.8239 - val_loss: 0.4917 - val_accuracy: 0.8413\n",
            "Epoch 163/250\n",
            "1406/1406 [==============================] - 30s 22ms/step - loss: 0.5448 - accuracy: 0.8222 - val_loss: 0.5304 - val_accuracy: 0.8306\n",
            "Epoch 164/250\n",
            "1406/1406 [==============================] - 30s 21ms/step - loss: 0.5358 - accuracy: 0.8263 - val_loss: 0.5008 - val_accuracy: 0.8409\n",
            "Epoch 165/250\n",
            "1406/1406 [==============================] - 30s 21ms/step - loss: 0.5402 - accuracy: 0.8237 - val_loss: 0.4840 - val_accuracy: 0.8455\n",
            "Epoch 166/250\n",
            "1406/1406 [==============================] - 31s 22ms/step - loss: 0.5358 - accuracy: 0.8262 - val_loss: 0.4873 - val_accuracy: 0.8452\n",
            "Epoch 167/250\n",
            "1406/1406 [==============================] - 31s 22ms/step - loss: 0.5362 - accuracy: 0.8262 - val_loss: 0.4945 - val_accuracy: 0.8425\n",
            "Epoch 168/250\n",
            "1406/1406 [==============================] - 31s 22ms/step - loss: 0.5325 - accuracy: 0.8279 - val_loss: 0.4943 - val_accuracy: 0.8411\n",
            "Epoch 169/250\n",
            "1406/1406 [==============================] - 30s 21ms/step - loss: 0.5347 - accuracy: 0.8264 - val_loss: 0.5194 - val_accuracy: 0.8371\n",
            "Epoch 170/250\n",
            "1406/1406 [==============================] - 31s 22ms/step - loss: 0.5290 - accuracy: 0.8265 - val_loss: 0.5144 - val_accuracy: 0.8359\n",
            "Epoch 171/250\n",
            "1406/1406 [==============================] - 31s 22ms/step - loss: 0.5272 - accuracy: 0.8287 - val_loss: 0.5032 - val_accuracy: 0.8394\n",
            "Epoch 172/250\n",
            "1406/1406 [==============================] - 31s 22ms/step - loss: 0.5273 - accuracy: 0.8271 - val_loss: 0.5218 - val_accuracy: 0.8338\n",
            "Epoch 173/250\n",
            "1406/1406 [==============================] - 31s 22ms/step - loss: 0.5258 - accuracy: 0.8295 - val_loss: 0.4695 - val_accuracy: 0.8499\n",
            "Epoch 174/250\n",
            "1406/1406 [==============================] - 30s 21ms/step - loss: 0.5301 - accuracy: 0.8272 - val_loss: 0.5001 - val_accuracy: 0.8390\n",
            "Epoch 175/250\n",
            "1406/1406 [==============================] - 30s 21ms/step - loss: 0.5218 - accuracy: 0.8298 - val_loss: 0.4842 - val_accuracy: 0.8449\n",
            "Epoch 176/250\n",
            "1406/1406 [==============================] - 29s 21ms/step - loss: 0.5248 - accuracy: 0.8286 - val_loss: 0.4834 - val_accuracy: 0.8432\n",
            "Epoch 177/250\n",
            "1406/1406 [==============================] - 29s 21ms/step - loss: 0.5214 - accuracy: 0.8315 - val_loss: 0.5206 - val_accuracy: 0.8346\n",
            "Epoch 178/250\n",
            "1406/1406 [==============================] - 29s 21ms/step - loss: 0.5270 - accuracy: 0.8295 - val_loss: 0.5031 - val_accuracy: 0.8411\n",
            "Epoch 179/250\n",
            "1406/1406 [==============================] - 29s 21ms/step - loss: 0.5214 - accuracy: 0.8288 - val_loss: 0.4883 - val_accuracy: 0.8425\n",
            "Epoch 180/250\n",
            "1406/1406 [==============================] - 30s 22ms/step - loss: 0.5292 - accuracy: 0.8275 - val_loss: 0.4812 - val_accuracy: 0.8478\n",
            "Epoch 181/250\n",
            "1406/1406 [==============================] - 30s 22ms/step - loss: 0.5245 - accuracy: 0.8289 - val_loss: 0.4929 - val_accuracy: 0.8407\n",
            "Epoch 182/250\n",
            "1406/1406 [==============================] - 31s 22ms/step - loss: 0.5188 - accuracy: 0.8321 - val_loss: 0.4925 - val_accuracy: 0.8433\n",
            "Epoch 183/250\n",
            "1406/1406 [==============================] - 30s 21ms/step - loss: 0.5132 - accuracy: 0.8318 - val_loss: 0.5304 - val_accuracy: 0.8345\n",
            "Epoch 184/250\n",
            "1406/1406 [==============================] - 31s 22ms/step - loss: 0.5187 - accuracy: 0.8306 - val_loss: 0.5226 - val_accuracy: 0.8349\n",
            "Epoch 185/250\n",
            "1406/1406 [==============================] - 28s 20ms/step - loss: 0.5174 - accuracy: 0.8300 - val_loss: 0.4743 - val_accuracy: 0.8489\n",
            "Epoch 186/250\n",
            "1406/1406 [==============================] - 29s 21ms/step - loss: 0.5132 - accuracy: 0.8329 - val_loss: 0.5062 - val_accuracy: 0.8399\n",
            "Epoch 187/250\n",
            "1406/1406 [==============================] - 29s 21ms/step - loss: 0.5122 - accuracy: 0.8325 - val_loss: 0.4769 - val_accuracy: 0.8461\n",
            "Epoch 188/250\n",
            "1406/1406 [==============================] - 30s 21ms/step - loss: 0.5091 - accuracy: 0.8323 - val_loss: 0.4824 - val_accuracy: 0.8441\n",
            "Epoch 189/250\n",
            "1406/1406 [==============================] - 29s 21ms/step - loss: 0.5166 - accuracy: 0.8303 - val_loss: 0.4740 - val_accuracy: 0.8476\n",
            "Epoch 190/250\n",
            "1406/1406 [==============================] - 29s 21ms/step - loss: 0.5131 - accuracy: 0.8324 - val_loss: 0.4825 - val_accuracy: 0.8460\n",
            "Epoch 191/250\n",
            "1406/1406 [==============================] - 29s 21ms/step - loss: 0.5122 - accuracy: 0.8337 - val_loss: 0.4717 - val_accuracy: 0.8479\n",
            "Epoch 192/250\n",
            "1406/1406 [==============================] - 30s 22ms/step - loss: 0.5152 - accuracy: 0.8322 - val_loss: 0.4714 - val_accuracy: 0.8500\n",
            "Epoch 193/250\n",
            "1406/1406 [==============================] - 29s 21ms/step - loss: 0.5141 - accuracy: 0.8332 - val_loss: 0.5107 - val_accuracy: 0.8398\n",
            "Epoch 194/250\n",
            "1406/1406 [==============================] - 29s 21ms/step - loss: 0.5076 - accuracy: 0.8330 - val_loss: 0.4781 - val_accuracy: 0.8457\n",
            "Epoch 195/250\n",
            "1406/1406 [==============================] - 29s 21ms/step - loss: 0.5042 - accuracy: 0.8358 - val_loss: 0.4859 - val_accuracy: 0.8457\n",
            "Epoch 196/250\n",
            "1406/1406 [==============================] - 29s 21ms/step - loss: 0.5064 - accuracy: 0.8332 - val_loss: 0.4965 - val_accuracy: 0.8407\n",
            "Epoch 197/250\n",
            "1406/1406 [==============================] - 30s 22ms/step - loss: 0.5063 - accuracy: 0.8343 - val_loss: 0.4688 - val_accuracy: 0.8485\n",
            "Epoch 198/250\n",
            "1406/1406 [==============================] - 30s 22ms/step - loss: 0.5046 - accuracy: 0.8336 - val_loss: 0.4995 - val_accuracy: 0.8445\n",
            "Epoch 199/250\n",
            "1406/1406 [==============================] - 30s 21ms/step - loss: 0.5046 - accuracy: 0.8345 - val_loss: 0.4684 - val_accuracy: 0.8503\n",
            "Epoch 200/250\n",
            "1406/1406 [==============================] - 30s 21ms/step - loss: 0.5011 - accuracy: 0.8352 - val_loss: 0.4678 - val_accuracy: 0.8519\n",
            "Epoch 201/250\n",
            "1406/1406 [==============================] - 31s 22ms/step - loss: 0.5010 - accuracy: 0.8370 - val_loss: 0.4896 - val_accuracy: 0.8430\n",
            "Epoch 202/250\n",
            "1406/1406 [==============================] - 30s 21ms/step - loss: 0.5030 - accuracy: 0.8346 - val_loss: 0.4865 - val_accuracy: 0.8460\n",
            "Epoch 203/250\n",
            "1406/1406 [==============================] - 31s 22ms/step - loss: 0.4999 - accuracy: 0.8349 - val_loss: 0.4818 - val_accuracy: 0.8477\n",
            "Epoch 204/250\n",
            "1406/1406 [==============================] - 31s 22ms/step - loss: 0.4997 - accuracy: 0.8386 - val_loss: 0.4949 - val_accuracy: 0.8448\n",
            "Epoch 205/250\n",
            "1406/1406 [==============================] - 30s 21ms/step - loss: 0.4916 - accuracy: 0.8389 - val_loss: 0.5445 - val_accuracy: 0.8293\n",
            "Epoch 206/250\n",
            "1406/1406 [==============================] - 29s 21ms/step - loss: 0.4983 - accuracy: 0.8383 - val_loss: 0.4627 - val_accuracy: 0.8522\n",
            "Epoch 207/250\n",
            "1406/1406 [==============================] - 31s 22ms/step - loss: 0.4935 - accuracy: 0.8395 - val_loss: 0.4776 - val_accuracy: 0.8488\n",
            "Epoch 208/250\n",
            "1406/1406 [==============================] - 30s 21ms/step - loss: 0.4908 - accuracy: 0.8382 - val_loss: 0.4765 - val_accuracy: 0.8447\n",
            "Epoch 209/250\n",
            "1406/1406 [==============================] - 31s 22ms/step - loss: 0.4919 - accuracy: 0.8390 - val_loss: 0.4691 - val_accuracy: 0.8481\n",
            "Epoch 210/250\n",
            "1406/1406 [==============================] - 30s 21ms/step - loss: 0.4993 - accuracy: 0.8382 - val_loss: 0.4539 - val_accuracy: 0.8540\n",
            "Epoch 211/250\n",
            "1406/1406 [==============================] - 30s 21ms/step - loss: 0.4892 - accuracy: 0.8408 - val_loss: 0.4537 - val_accuracy: 0.8543\n",
            "Epoch 212/250\n",
            "1406/1406 [==============================] - 30s 21ms/step - loss: 0.4917 - accuracy: 0.8374 - val_loss: 0.4546 - val_accuracy: 0.8539\n",
            "Epoch 213/250\n",
            "1406/1406 [==============================] - 30s 21ms/step - loss: 0.4897 - accuracy: 0.8404 - val_loss: 0.4615 - val_accuracy: 0.8506\n",
            "Epoch 214/250\n",
            "1406/1406 [==============================] - 31s 22ms/step - loss: 0.4935 - accuracy: 0.8388 - val_loss: 0.4771 - val_accuracy: 0.8497\n",
            "Epoch 215/250\n",
            "1406/1406 [==============================] - 30s 21ms/step - loss: 0.4901 - accuracy: 0.8382 - val_loss: 0.4898 - val_accuracy: 0.8448\n",
            "Epoch 216/250\n",
            "1406/1406 [==============================] - 31s 22ms/step - loss: 0.4925 - accuracy: 0.8415 - val_loss: 0.4763 - val_accuracy: 0.8497\n",
            "Epoch 217/250\n",
            "1406/1406 [==============================] - 30s 21ms/step - loss: 0.4926 - accuracy: 0.8396 - val_loss: 0.4597 - val_accuracy: 0.8507\n",
            "Epoch 218/250\n",
            "1406/1406 [==============================] - 30s 22ms/step - loss: 0.4786 - accuracy: 0.8443 - val_loss: 0.4689 - val_accuracy: 0.8511\n",
            "Epoch 219/250\n",
            "1406/1406 [==============================] - 30s 21ms/step - loss: 0.4833 - accuracy: 0.8420 - val_loss: 0.4816 - val_accuracy: 0.8478\n",
            "Epoch 220/250\n",
            "1406/1406 [==============================] - 31s 22ms/step - loss: 0.4828 - accuracy: 0.8420 - val_loss: 0.4900 - val_accuracy: 0.8458\n",
            "Epoch 221/250\n",
            "1406/1406 [==============================] - 30s 21ms/step - loss: 0.4818 - accuracy: 0.8423 - val_loss: 0.4612 - val_accuracy: 0.8521\n",
            "Epoch 222/250\n",
            "1406/1406 [==============================] - 30s 21ms/step - loss: 0.4845 - accuracy: 0.8406 - val_loss: 0.4965 - val_accuracy: 0.8427\n",
            "Epoch 223/250\n",
            "1406/1406 [==============================] - 31s 22ms/step - loss: 0.4823 - accuracy: 0.8417 - val_loss: 0.4571 - val_accuracy: 0.8572\n",
            "Epoch 224/250\n",
            "1406/1406 [==============================] - 30s 22ms/step - loss: 0.4836 - accuracy: 0.8406 - val_loss: 0.4610 - val_accuracy: 0.8537\n",
            "Epoch 225/250\n",
            "1406/1406 [==============================] - 31s 22ms/step - loss: 0.4772 - accuracy: 0.8414 - val_loss: 0.4845 - val_accuracy: 0.8462\n",
            "Epoch 226/250\n",
            "1406/1406 [==============================] - 30s 22ms/step - loss: 0.4804 - accuracy: 0.8411 - val_loss: 0.4809 - val_accuracy: 0.8472\n",
            "Epoch 227/250\n",
            "1406/1406 [==============================] - 30s 22ms/step - loss: 0.4850 - accuracy: 0.8414 - val_loss: 0.4721 - val_accuracy: 0.8491\n",
            "Epoch 228/250\n",
            "1406/1406 [==============================] - 30s 21ms/step - loss: 0.4775 - accuracy: 0.8433 - val_loss: 0.5307 - val_accuracy: 0.8325\n",
            "Epoch 229/250\n",
            "1406/1406 [==============================] - 31s 22ms/step - loss: 0.4804 - accuracy: 0.8442 - val_loss: 0.4821 - val_accuracy: 0.8475\n",
            "Epoch 230/250\n",
            "1406/1406 [==============================] - 31s 22ms/step - loss: 0.4764 - accuracy: 0.8433 - val_loss: 0.4541 - val_accuracy: 0.8556\n",
            "Epoch 231/250\n",
            "1406/1406 [==============================] - 31s 22ms/step - loss: 0.4755 - accuracy: 0.8438 - val_loss: 0.4660 - val_accuracy: 0.8531\n",
            "Epoch 232/250\n",
            "1406/1406 [==============================] - 31s 22ms/step - loss: 0.4769 - accuracy: 0.8434 - val_loss: 0.4681 - val_accuracy: 0.8527\n",
            "Epoch 233/250\n",
            "1406/1406 [==============================] - 31s 22ms/step - loss: 0.4753 - accuracy: 0.8452 - val_loss: 0.4492 - val_accuracy: 0.8573\n",
            "Epoch 234/250\n",
            "1406/1406 [==============================] - 31s 22ms/step - loss: 0.4723 - accuracy: 0.8464 - val_loss: 0.4526 - val_accuracy: 0.8556\n",
            "Epoch 235/250\n",
            "1406/1406 [==============================] - 31s 22ms/step - loss: 0.4730 - accuracy: 0.8453 - val_loss: 0.5162 - val_accuracy: 0.8375\n",
            "Epoch 236/250\n",
            "1406/1406 [==============================] - 30s 21ms/step - loss: 0.4703 - accuracy: 0.8476 - val_loss: 0.4552 - val_accuracy: 0.8560\n",
            "Epoch 237/250\n",
            "1406/1406 [==============================] - 30s 21ms/step - loss: 0.4699 - accuracy: 0.8448 - val_loss: 0.4736 - val_accuracy: 0.8507\n",
            "Epoch 238/250\n",
            "1406/1406 [==============================] - 31s 22ms/step - loss: 0.4691 - accuracy: 0.8456 - val_loss: 0.4802 - val_accuracy: 0.8523\n",
            "Epoch 239/250\n",
            "1406/1406 [==============================] - 31s 22ms/step - loss: 0.4680 - accuracy: 0.8469 - val_loss: 0.4784 - val_accuracy: 0.8517\n",
            "Epoch 240/250\n",
            "1406/1406 [==============================] - 31s 22ms/step - loss: 0.4690 - accuracy: 0.8446 - val_loss: 0.4639 - val_accuracy: 0.8543\n",
            "Epoch 241/250\n",
            "1406/1406 [==============================] - 31s 22ms/step - loss: 0.4721 - accuracy: 0.8451 - val_loss: 0.4627 - val_accuracy: 0.8534\n",
            "Epoch 242/250\n",
            "1406/1406 [==============================] - 31s 22ms/step - loss: 0.4672 - accuracy: 0.8479 - val_loss: 0.4670 - val_accuracy: 0.8533\n",
            "Epoch 243/250\n",
            "1406/1406 [==============================] - 31s 22ms/step - loss: 0.4725 - accuracy: 0.8459 - val_loss: 0.4540 - val_accuracy: 0.8561\n",
            "Epoch 244/250\n",
            "1406/1406 [==============================] - 31s 22ms/step - loss: 0.4774 - accuracy: 0.8441 - val_loss: 0.4704 - val_accuracy: 0.8537\n",
            "Epoch 245/250\n",
            "1406/1406 [==============================] - 31s 22ms/step - loss: 0.4680 - accuracy: 0.8448 - val_loss: 0.4421 - val_accuracy: 0.8597\n",
            "Epoch 246/250\n",
            "1406/1406 [==============================] - 31s 22ms/step - loss: 0.4624 - accuracy: 0.8483 - val_loss: 0.4593 - val_accuracy: 0.8547\n",
            "Epoch 247/250\n",
            "1406/1406 [==============================] - 31s 22ms/step - loss: 0.4720 - accuracy: 0.8457 - val_loss: 0.4537 - val_accuracy: 0.8567\n",
            "Epoch 248/250\n",
            "1406/1406 [==============================] - 30s 21ms/step - loss: 0.4688 - accuracy: 0.8458 - val_loss: 0.4644 - val_accuracy: 0.8519\n",
            "Epoch 249/250\n",
            "1406/1406 [==============================] - 30s 21ms/step - loss: 0.4734 - accuracy: 0.8468 - val_loss: 0.4745 - val_accuracy: 0.8499\n",
            "Epoch 250/250\n",
            "1406/1406 [==============================] - 31s 22ms/step - loss: 0.4653 - accuracy: 0.8478 - val_loss: 0.4807 - val_accuracy: 0.8489\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate model\n",
        "_, acc = model.evaluate(x_validation,y_validation, verbose=1)\n",
        "print('> %.3f' % (acc * 100.0))\n"
      ],
      "metadata": {
        "id": "5oP_5ojUlzE1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f0f3385-22f0-4664-d696-6aa300abdfe7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "469/469 [==============================] - 2s 4ms/step - loss: 0.4807 - accuracy: 0.8489\n",
            "> 84.887\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# learning curves\n",
        "summarize_diagnostics(history)"
      ],
      "metadata": {
        "id": "YqVjalPgn69O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "44b281f2-ae6f-48cf-b62e-4358da0f4ad5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydeXhV1dWH35V5IIQEQggkJEAAAQEZBUQFBEGchzrjUMXaOg9VWzv4tdY612q1TqVVcaozIgKiIIqABARkkHkIkBAgIQmZk7u/P9ZJkwBhDFxuWO/z3Cc35+yzz9rn3vs766y99t7inMMwDMMIfIL8bYBhGIbRMJigG4ZhNBJM0A3DMBoJJuiGYRiNBBN0wzCMRoIJumEYRiPBBN0wDKORYIJuHDIicqWIZIjILhHJEpHPRWSwH+1ZLyIlnj3Vr38c4LEzROTGI23jgSAi14nIt/62wwg8QvxtgBGYiMjdwAPAzcAUoBwYBZwP7CFGIhLinKs8Cqad65yb1tCVHkX7DeOQMQ/dOGhEJBb4E3CLc+5D51yRc67COfepc+7XXpmHROR9ERkvIgXAdSLSWkQmiEiuiKwWkbG16uzvefsFIrJVRJ72tkd4dewQkZ0iMk9EEg/B5utE5FsReVJE8kRknYic5e37C3Aq8I/aXr2IOBG5RURWAau8bWM923O9trSudQ4nIreLyFoR2S4iT4hIkIiEeeW71yrbUkSKRSThINsxyLsG+d7fQbu1ca2IFHrtu8rbni4iX3vHbBeRdw/2+hkBgnPOXvY6qBfqiVcCIfso8xBQAVyAOg6RwEzgBSACOAnYBgzzys8GxnjvmwADvPe/AD4FooBgoA/QtJ5zrgeG17PvOs+esV49vwS2AOLtnwHcuNsxDvgCiPfsHwZsB3oD4cBzwMzdyk/3yrcFVlbX6bX7sVpl7wA+3Yet3+5lezyQB4xBn66v8P5vDkQDBUBnr2wS0M17/zbwoPc5RACD/f0dsteReZmHbhwKzYHtbv8hiNnOuY+dcz6gBXAKcL9zrtQ5txB4FbjGK1sBpItIC+fcLufcnFrbmwPpzrkq59x851zBPs75sefJV7/G1tq3wTn3inOuCngNFb39eft/dc7lOudKgKuAcc65Bc65MuA3wEARSatV/jGv/EbgGVR08c53hYiI9/8Y4I39nHt3zgZWOefecM5VOufeBn4CzvX2+4ATRSTSOZflnFvqba8AUoHW3rW3+HwjxQTdOBR2AC1EZH99MJm13rcGcp1zhbW2bQDaeO9vADoBP3mhhHO87W+gMfp3RGSLiDwuIqH7OOcFzrlmtV6v1NqXXf3GOVfsvW1ykG3YUKuOXei1aFNP+Q3eMTjn5gLFwBAROQFIBybs59y7U+f8tc7RxjlXBFyG9mlkichn3nkA7gME+F5ElorIzw/yvEaAYIJuHAqzgTI0nLIvak/luQWIF5GYWtvaApsBnHOrnHNXAC2Bx4D3RSTaaWz+/5xzXYFBwDnUePUNSX3Tju7ehtTqf0QkGn162FyrTEqt9229Y6p5Dbga9c7fd86VHqSNdc5f6xzV13CKc24E+uTxE/CKtz3bOTfWOdcaDWG9ICLpB3luIwAwQTcOGudcPvAH4HkRuUBEokQkVETOEpHH6zkmE/gO+KvX0dkD9crHA4jI1SKS4IVndnqH+URkqIh0F5FgNEZcgYYWGpqtQPv9lHkbuF5EThKRcOARYK5zbn2tMr8WkTgRSUHj5LU7IMcDF6Ki/vp+ziXedfrfC5gEdBJNFw0RkcuArsBEEUkUkfO9m0wZsAvvOonIz0Qk2as3D71JHYlraPgbfwfx7RW4LzSmnAEUoeGMz4BB3r6HgPG7lU8GJgK5wBrg5lr7xgM5qBAtRUMnoDHoFd45tgLPUk9nLNopWuLVUf36yNt3Hbt1NKLClu69H4h2YuYBz+6+v9YxN3u253ptSd6tvtuBtWgo5ikgeLfjp3l2yj6u63VeXbu/QoDBwHwg3/s72DsmCfja274T7eTt6u17HPXid3m23+Tv7469jsyruoffMIzDREQc0NE5t3ofZcYBW5xzvzt6lhnHCzawyDCOEl42zEVAL/9aYjRWLIZuGEcBEfkzsAR4wjm3zt/2GI0TC7kYhmE0EsxDNwzDaCT4LYbeokULl5aW5q/TG4ZhBCTz58/f7pzb6xxAfhP0tLQ0MjIy/HV6wzCMgEREdh8t/D8s5GIYhtFIMEE3DMNoJAScoL/wAiQmQlmZvy0xDMM4tgg4Qa+qgpwcKCzcf1nDMIzjiYAT9Bhvrr6Cfc2IbRiGcRwScILetKn+NQ/dMAyjLgEr6OahG4Zh1CXgBN1CLoZhGHsn4ATdQi6GYRh7J+AE3Tx0wzCMvRNwgm4eumEYxt4JOEFv4q3Rbh66YRhGXQJO0IOCVNRN0A3DMOoScIIOGnaxkIthGEZdAlLQY2LMQzcMw9idgBR089ANwzD2JGAF3Tx0wzCMugSkoFvIxTAMY08aRNBFJEVEpovIMhFZKiJ3NES99WEhF8MwjD1pqDVFK4F7nHMLRCQGmC8iXzjnljVQ/XUwD90wDGNPGsRDd85lOecWeO8LgeVAm4aoe29Ue+jOHakzGIZhBB4NHkMXkTSgFzC3oeuupmlTqKyE0tIjdQbDMIzAo0EFXUSaAB8Adzrn9giKiMhNIpIhIhnbtm075PNUT9BlcXTDMIwaGkzQRSQUFfM3nXMf7q2Mc+5l51xf51zfhISEQz6XLXJhGIaxJw2V5SLAv4DlzrmnG6LOfWFT6BqGYexJQ3nopwBjgGEistB7jW6guveg2kPPzz9SZzAMwwg8GiRt0Tn3LSANUdeBkJ6uf5cvh6FDj9ZZDcMwjm0CcqRoSgokJMC8ef62xDAM49ghIAVdBPr1g4wMf1tiGIZx7BCQgg4q6MuWQVGRvy0xDMM4NghoQff5YMECf1tiGIZxbBB4gr7uTZjcn759qgCYe8TGoxqGYQQWgSforgpy55EYuYKuXWHyZH8bZBiGcWwQeILevK/+3ZHBOefA11/bACPDMAwIREGP6Qwh0ZCbwbnn6iRdU6b42yjDMAz/E3iCHhQMcb0hN4MBAyA+HiZM8LdRhmEY/ifwBB2geT/I+4GQoArOO08FvazM30YZhmH4l8AU9Pi+UFUKuQu47DKNoVvnqGEYxzuBKeithkNYHGTcwhlDy2neHN55x99GGYZh+JfAFPSIBDj5X5A7n9BvR3Hz1WuZMMFGjRqGcXwTmIIOkHIh9H8Fcudzz+CfU1wMn33mb6MMwzD8R+AKOkD6jdDxFppVfEvHtHzefdffBhmGYfiPwBZ0gKSRiKvi/mu/4rPPbNELwzCOXwJf0FsMhJAYzu03hbIyeO01fxtkGIbhHwJf0IPDoNUwWlZOYeBAx3PP6SyMhmEYxxuBL+gASSOhaD0P3raK1ath4kR/G2QYhnH0aTyCDozqOYW0NHjkEXDOvyYZhmEcbRqHoDdpDzEdCc6ZzAMP6Bzp06b52yjDMIyjS+MQdFAvfesMrhtTRtu2cNttUFzsb6MMwzCOHo1H0FufDVXFhO/4nHHjYOVKuPtufxtlGIZx9Gg8gt5qOEQmwdpxnHEG3HsvvPQSfPyxvw0zDMM4OjQeQQ8KgXbXwJZJUJLNww9D795w442wZYu/jTMMwzjyNB5BB2h/PTgfLPotYaGOt96CkhK49lrLTTcMo/HTuAS9aWfo9ltY+2/4MJHOmUN45hnHtGnwwAP+Ns4wDOPIEuJvAxqc7g9B0QYoXAU5X3PjOdNZ+KthPPEEtG8PN9/sbwMNwzCODI3LQweNpQ96A4bPgIiWyE9P8OyzMHo03H675qgbhmE0RhqfoFcTHAGd74SsyQRvHM97Dz3C6Sct48wzbWoAwzAaJ41X0AFOuEfXH509hqhVDzLpt5fSpXM5T943k+K3kqEky98WGoZhNBiNW9CDw2Dwu5B8AZz4R0KLlzLzxSf47WWvEMVm3v37VEpK/G2kYRhGw9C4BR10npfTPoIeD0HyhYStfpQRXSYAULxuBh06wHvv+ddEwzCMhqDxC3ptej4MlUVIZQFEJHLFsOkkJ8Oll8I/HluHb9lTNk2jYRgBy/El6LFddTRpREvoch8RVRv4ZvI6rrwS8ue/StDCe8nZkOlvKw3DMA6J40vQAfq/BKN/hNajAAjP/i/jx8PlZ68C4PZrlzFlij8NNAzDODSOP0EPDlcPPbarztC45C9IaRYdElYC0KfDMkaNgquugtmzbcoAwzAChwYTdBEZJyI5IrKkoeo84vT+G/hKYemjOrIUuOuGZdx/P0yYAIMGQXq65q1baN0wjGOdhvTQ/wOMasD6jjxNO0LiGbDhLajS1TBCdi3l0Udh0yYYPx4iIuDcc2HAAPjySz/baxiGsQ8aTNCdczOB3Iaq76iROAzKtuv7pp2hYBk4R2yshl0WLoQXXoCcHBg+HM48U4V+1Sr/mm0YhrE7RzWGLiI3iUiGiGRs27btaJ66fhKH1rxPvgAqCqB40/82hYXBL38Jy5fDY4/BkiUwZgx06qRzrc+fb+EYwzCODY6qoDvnXnbO9XXO9U1ISDiap66fuF4QGqtzv7Q+W7d91g3WvQn5y2HzZ4CGXu67DzZsgB9/hHvugddeg759YeBAePNN9dpN3A3D8BfHX5bL7gQFQ9IoaHYSJAyG0z+DZifC3Btg6iCYeR4U1yx5FBoKJ54ITz4JWVkajtm8Ga6+Wr325s3hssvUczcMwziaiGtAl1JE0oCJzrkT91e2b9++LiMjo8HOfVhU7AJXCWHN9P/SbTC5t65+VLIFej4C3X5T7+GVlRqKyciAWbM0KyY3F4YNg3794Kyz1IsPaXyzzxuGcZQRkfnOub573ddQgi4ibwNDgBbAVuCPzrl/1Vf+mBL0vVGWC0Gh8PU56qGfuwK+PlcXou77Dw3R1MPOnfDwwzB9OixerIIfHQ1xcTov+913Q+fOR7EthmE0Go6KoB8sx7ygV7PuDZh9DXT5NSx/Qrc1HwCDxkPFTg3VBAXXe3h+PnzxBXzzDWRnw8cfQ3k5tG0LLVvCGWdo52p6+lFqj2EYAY0J+uHgq4BPO0PROghtBn2fg+9/8b+8dZLPh0FvQkj0AVW3ZQu8+67G2Ddt0hCNz6edqyeeCD17wtCh+l7kCLbLMIyAxAT9cFn7H5hzPXS+A/o8A3mLYNMEwAdL/gQth8KQzzQOX7gK4k6qv67lT0NoDKSPBdRrf/55+O47jcPn5GixxET14Hv0gLFjITkZEhKgadMj3lrDMI5hTNAPF18lrHwO0q7SeWBqUx2SiUyCyiLNYx8yGVqP9PaPh0UPwtlLAQcfttQ0yQs27zVUs2FdBRtnvsF/pl/J9rwIvvoKdu2q2d+rl2bUjB6tGTeJidDEtwKi2kJI5JG7BoZhHBOYoB9pNr6nHntwOGR/qYJ91gJA4POesPNHGPxfqCqD2WP0mBGzIGHQnnWtfwe+uwJOehy6/prcXJgzB7Zvh8xM+PTTugtdx0XnkfVCElM33s0n6x8hJQVuvlmF3jCMxocJ+tFk/dvw3ZXQ5T5IuRCmDtTtqVdA+U7YuQjKtkH6LyD9ZojtAlJrOMC3l+oNIqIVnL+ubjaNcyDCokWwdEkloZVb8eV8x2VtLmV1zgkMeXI5Wd4yqYmJUFam2TTDhkFqKpx3HgQHQ3w8BNkIBMMISEzQjybOB/N+CatfBgmGoHBocw5s+gR85dD1Acj7AbIma/km7WHAa9ByMFSWwIcJ0KQD7Fysc7en36Tldq2DL06FE+6GLnfDsidg8e+gxUDI+VrLnLOSldkdeftt9eZDQ3UK4MWL645gbdtWO18jIqBPH6ioULHv0ePoXirDMA4eE/SjjXOw/i3YuRCanwyhTWH6yJqMmPzlkPkhRLeF5U9BWY6upFS4CrKmaAx+8e+hPBfOWaGx9u+ugfVvaP2D3tYUyrwF+n/zk2HHXOj1lIp96TYN9fR/Bdqcjc+nHa6TJ+vgpi+/1NGteXmwcWON2R07QlWVxuzPOUenD54zB2JidPRrVZVm44SFHf1LahiGYoJ+LJC3CGJP3LMjtCgTvhquE4JFtYHoNDh9ImyZCN9crOLdJE2nIeh0G+z4HgpXQHmeevK71sDJ42DFMyAhMCoD1o/XjtpWw2HYF/Wa5JzmyVdWwssvqycPmi45aRIUFECTJlBaqmVAs2xGj9YbQ3W6ZXS0hnSSk6FVKw3pWMqlYRwZTNCPdZy3LFLtWLrzwaTusGstSCiEx8OoBVCwAr7wOlPPXgrZX0GHG2D9m/D9WBjyuWbebHgLEI3DR6fu34byPAiOhmB1v6uqYOVKDc/s2FEzN81nn8G3X+6g3NeEkvJwsrP3rCo+XueQ79FDnwLWrtWUy6uugq1b4ZRT9GYRHq43AMMwDhwT9ECleDP8cC8UroFTP4DoFN0+6yoozoQRM2vKVpXDpx0hIgGKNugSeznfQPP+0Pl2SLtSXfI1r0CzHrD1K9g2G/q/CEUbNSSUNAIGv6fzw++enllNxS49T3gL3JAp7ChpTUkJrF+vg6ays2HePA3v7NihnbApKRriqajQKoKCapb2GzAARozQ982aqcA3bw5RUfp00KGD5d4bRm1M0BsbzgfInnGNje/BrMt1/8DxUJoFq17UsEyvJ6GiEJb8X015CYagMO2sDQqFqlK9AeQt1KeBZt32PPeyx2Hh/RAcqSGkUd9r7n1IE33C8FVCeR4uPIHcXIiN1fDM+vU6KjYpCaZN0yycXbt0KoT9fQ26dYP27TX0k5+vdY0YARdeqNsjIrSPoFUr7eQNDdWbR1TUYV5nwzgGMUE/ntj0qWbYDHpDZ4/0VcDMizQmD5B6OcR0hLDmGmNf9by+73A9fHEalGxWsY7rBc376aIfmR/Bxneg1QidH77FydD6HJh/G/R9Xv8GhcHJ/4bts2Hlsyr2QyYCAmHxENqkXpPLyiAs1FFQKGRl6UyVJSUq3suXw8yZOoI2PFy99pYtNR+/9oCraiIi9AnAObjoIli3Tjt+O3aEkSOhdeuaUbgFBRBZMo/WobMpSLqd9eu1H0BEO347drS+AOPYwwT9eMdXAVun6wySKRfUP1Nk7nwoyYbijTDvV95GARzE99UwT0xHTacMbwkfJQE+fR+RoHH4slyI762dwNGpsGu1ivuIb1Rly7bryNmkEVCwEnIz4KRHYcZo6DAWuv9RVbQoE1b9U9M0I1rojJeZ7+tTRZP2FDUdyarVQaxdC4WF0KNLPm3WX8b0VRfzXc5Y8vLgk0+ge3f14ufO1T6B2gRJFT8+1p2ubZbT//dzmbe2f539CQlw8sk6mZpzeiNo315DQN266ba8PH0BnH66bj+om4A3tsAwDhQTdOPgcD6Nscd0gvl3QHhz6P9y3U5bgK/Pg82fQp/nNJ/+a2/Fp7MWathmznXQJF1FPSxOBV+CwVXVrSc4Cnylet4T7oGUi2Hm+ToAq8MN0PcFmNJPc/Or6Xq/3ghAQ0XfXaWpoAgMGKcDs1a/rFMdR7XGORX+3PUriF77EPMrHyEl/Gu6FV6PjxC2uFGsa/spmZka9y8s1BkyFyzQ0I0IFOzIJ7hsI0syu9d76ZKSVPirqqBpU0efPkJoqGYJVVZqP0NREfz611BcDP12jaIyOIEfY94gPFyfLtatg65dtX+hqqpmvv3kZBsBbJigG0eKbbNgxd9h4Os6gGrKyZqNM3Syep45X6tnv+oFfd+8P1TuUk888wMIiYHClTpPzoB/w44MDQEFhencNC1O1nz+ViMge6p22CYM1o7iDe9CqzP0SaCyUOfR6fFnyJoK276psTHhVEgaCeEttKM341ZdtCRxGOQvgahUSD5P8/5Tr9TO48RhdefFKd6iN7XpI3HbZpE/IIPFmT0JDdU57uPiNL4/98u1fPJlOwoLhWt6Pkjvlp8w/K/TyCloRUiI9iU0bw6FhY687aX0breAWX8cTFFpFPG/yKW8MrzO5Y2J0RtLaHA5FVWafZSYqB3KxcU69fJFF+nNZu5c2J5TxWlDgtm5U21KSNAwVevWGp5KT4c2beo+EJSXa59DfQ8JdR4gfBWaGnuknygqS2DBndD5Th1JfTSo8vqRAuBpyQTdODpUlugPYh+Lf+yBr1K9+fg+6qHPukw7cYdMUs99cl8dYNXhBuj1uB5TmgMTu2j5lAu0Qzb5fEg8Q73/Nf/SQVoxHWHezXXPF5mk8f81r2hfwch5EJMOP/6f5vJXlehsmf1e1JuPr0KfFsLioTRbbzaxXaHb72DpwxDbDfo8C0sfgZ+egjbnalt+fEjPF99XZ+lsNRwiW8GmCfjm3EhQ+TbKgxII9W1HcKxK/C/hxQsJqsyjosOdfD4zjYLMJQxLHUf/Zs+znUF8suV5vl91Em2ilzAy5VF+++Zv+Gq+dlw/eNET3HvWXxn56Od8v+bkOk2OCC3h9pHPUlIRydQfR9E1ZQ3DTpzO41MeYdPmENLSdBxBk6BNjOn/LP+YchNVkels2qT9Gb16wbABm7i/Zx8qfaF8ufUPrAu+ifR0vcHEx8PSpZqSmpys/Q9bt0IwJbRNDaJPv3DC696r9s2yJ2DhfTo9Rv8XD+LAQ6SiAD7tpKOye/xp72XK89VRaHPOkbdnP5igG4FD9fdxf55SSZYKfljsvsvlfKuCXboVKvJ1qgTn0/l22l4KqZfVlK0s0k7fOdepsFfT9AQV95iO0Ol2+PZnOlVyREsdlYtnc9IoDVX5yqHl6dDxVzrtclUxIHq+7KkQlQyJw2HNq9DlXlj6F93vKvSGEdFKb4oFP2m9qVdCznR9P/ANrbM4ExccSVb8g1RGnUDKxssBH77gOMr7/5dc+lCRNQcp/Ino3A9o4av11OLx2vKX6NByJRmruvPRwit5/sKhnJg4i4qqMN784X6mbLyP9ikFhOTNYHjqS/RKnc+STSfSK/UHHnjnUW4Z8TzXvPg6s1ftOclcRGgJ8/7cDxHH4D99R6fU7Yzs+hFvzbqc/h3m0bH1et5ZeCdNmgipLbdQXlbJzrJkuqZu5G8jexEdupPCipY8snwLHdKDad1aby7ffafzE/XooR3nERGaEpvULJugsCjyi5sSFQXDh2vojKJMCInScOHG96DdtTqJXm2WPw0/3KNPmeeu1BHcu5Nxuz5JnjkbWgzY93fuCGOCbhgHw84fIXeBZgnlzNS4fkQi4NPH8tJt2pnbYpA+XWz7RnP725yrTxOVxTrqV4LUw89fqpO2/fS0Hn/WQmjaqebm9dUI2PolnPQYJA6FaadpOKrXkyoeTTupTVMH6k0nJBoGv699BJs+0jqikuHUD2HWldpnUZugcO1XSDhVRxFXi1vuAv53MwoKB18Z9P4b7JinA9OCQtVGp8OEs1LHEZ56JnGzOiLeDa+CWApdKkQkEtGkKa5wNdsiLiIu+Cdi897GRzAllXFEh2zXS1ueTExoFsFSxfsr/kjerliu73UfIUGVlFVGECSVVPpCeOLTX/OHi/7Mi1/+ktjIPLYXtuCrZcOYtvxcdhXVLM6blrCORy79LZcO+C+FJTE8PvE+npt6G9ed+Tk/H/gUvdp+z+adKWzY3oFB6TP4+7Tf8NTkB3n1xusZ2G4aq7aeQOvYtRSUJ5EWt5yMLSP59+oPaR27gdjIneT6ehAdUcLd7dsQHlTI6vJLyOZMUkM/IyIol+KQzqwJv58N29vRvlUmuUUtWbK4nPCyZXQ9bRCnnKLjMrZtc7QKmUv8rnfpHPctkf0eRFIuOKSvpwm6YRwL7FyqgtyibjYNmydqamj/lyAoREcDh8XtObgrf7kKe8IpesMAyP1BO5vje+kxlSUaTqoqg2bdNeQTEr3nXPlbpsCMszSrKKaTZjjFdtHQFsD2OWqTiKa6hifUnPOnZ2Dd6xqWWvSA3gyK1umgs+i2mroK0PkuiOupN5FWwzU8NetKiOkA0e1qbkatR2vIrGAlSDCu4y2s29Kcdj8kIFUlVISnEVS+nWC3C9e0KztDB1NcVEW0bKJpyXQICiE75leEl6+ieckn+AgiCB9Zuzoxf8cVDGv9N6JCC8gu6UbLiOUUVrSkSUgOU366kk5JK2jfbD53TZhM++ZLuWPwXWTltyYpdgsA89b2Y/HG7twwZBxfLR3KsG76pLQ6uwOb89rQr/08osJrnuZ2FMZT6QshMTaHxz69jxOTl1DlC6Z9y7WcmLKUkvII5q4+mdxW93HRraMP6Wtkgm4Yxp6UbtN004ambIfeUKJa77mvJFsnqwsK84TfQYtT9r4u75bJ+pTQ6gx90tn8qfZNlOZo52x4vPabdLlHn1BAb1RZk7UjPWmk1pu7QOdASrtSw1USCh1+Dkln6jFVZTVhmKWPwMYPoP21auOi30J5HlVJ57Ory/NELriagpY3kNf0KkrLBF/RFpoVvEvTiAK2FSaSUPk5TaNLkOBwgrImUlSVQFVIC0KimrE95ucEtbuML2bEcOqph76OsAm6YRjGoVBZon0i++ur2Z2qctj4rj59hDdvUJP2Jeghe9toGIZh4IWqDmFpx+AwaDemwc3ZH7ZujWEYRiPBBN0wDKOR4LcYuohsAzYc4uEtgO0NaE4gcDy2GY7Pdlubjw8Otc2pzrm99mb7TdAPBxHJqK9ToLFyPLYZjs92W5uPD45Emy3kYhiG0UgwQTcMw2gkBKqgv+xvA/zA8dhmOD7bbW0+PmjwNgdkDN04uojIQ0C6c+7qI1T/UuAW59wMERFgHHABsAq4B3jVOde5gc/ZFlgGxDq3+wTthhGYBKqHbjQwInKliGSIyC4RyRKRz0Vk8NE4t3Oum3NuhvfvYGAEkOyc6++c+6YhxFxE1ovI8Frn3Oica3KkxFyUtSKy7EjUbxh7wwTdQETuBp4BHgESgbbAC8D5fjAnFVjvnCvyw7kbktOAlkB7Eel3NE8sIjYC/HjFORdQL2AUsAJYDTzgb3uOYDvXAz8CC4EMb1s88AUaivgCiGuA88QCu4Cf7aPMQ8D4Wv+/B2QD+cBMoFutfaPRUEYhsBm419veApgI7ARygW/Q0EoOUA4MB24AStE5XX3AGuAcYBO6uOmz3nXJB/KAHcA/vJCQ70EAACAASURBVPo7AF9527YDbwLNvH1vePWVeG29D0jzzhPilWkNTPBsWw2M3a39/wVe99q1FOi7n+s6zrPhw2oba23f4dmRC2wFvvSu1UJgC5DlnWc+8KjXZgecVaueGcCN3vvrgFnA37y6H97X9fCOSfFs21Z9HYEwz6butcq1BIqBhMP4jqUA073vxVLgjn19n2t91quBxUBvf/8eG7DND9X6rBcCo2sd8xuvzSuAkYd0Xn83/CAvUjD6I2/vffkWAV39bdcRaut6oMVu2x7Hu4kBDwCPNcB5RgGV1cJWT5mHqCvoPwdigHDUs19Ya18WcKr3Pq76xwj8FXgRCPVep6JebG88QffKTUI99Oo2voUK+mjgc+8zfxuYB0QAg72y6WioJhxIQG80z+x2PYfX+j+NuoI+E30qiQBO8oRuWK32l3o2BHttmbOP6xUFFHjlL0YFNczbN9KrO8s7VwzwCnAv8Gv0Jt4ZFbULgSVAJ8/WNUCwV88M6gp6JXAbOj9T5L6uh9eGRegNIHq36/hC7e8VcAfw6WF+x5JqfQ9igJVAV+r5Ptf6rAUYAMz19++xAdv8EJ6Ts1v5rt5nEg60q/1ZH8wr0EIu/YHVzrm1zrly4B38ExbwF+cDr3nvX0M7Dg+X5sB257xVDA4A59w451yhc64M/YL2FJHq6egqgK4i0tQ5l+ecW1BrexI6yq3CaWx8JuoR1qYX6rWCtrE6jn8+MBv1pMcATVGP7lvPptXOuS+cc2XOuW3A08DpB9IeEUkBTgHud86VOucWAq8C19Qq9q1zbpLTmPsbQM99VHkRUAZMBT5Db2DeCtrEo08lO7xzVT/JANwI/M45t8Lpr/wE1LMu9/avQX8De2OLc+4551ylc65kP9ejP3odf+2cK/Ls+Nbb9xpwhdc5DXqt39hHW/eLcy6r+nvgtXc50Ib6v8/nA687ZQ7QTESSDseGo80+2lwf5wPveJ/XOtRTr++zrpdAE/Q2QGat/zex74sUyDhgqojMF5GbvG2Jzrks7302Gu8+XHYALQ407ioiwSLyqIisEZEC1PMFDamAeqSjgQ0i8rWIDPS2P4F+Sad6nYUP1HOKWFT8QdsY771vg16TDd7Np85nLyKJIvKOiGz27Bpfy6b90RrI9X541Wyg7ncru9b7YiBiH9fsWuC/nriWAh9420Afxfc25cWtQEfgWhGJ87YdzPe9drn9XY8Uaq5jHZxzc732DRGRE1BPf0I95zxoRCQNvWnPpf7vc6P6ne/WZoBbRWSxiIw7xM+6XgJN0I8nBjvnegNnAbeIyGm1d3oeXEPknM5GvckD9favRL2J4aj4pnnbxbNrnnPufDT2+jEae8bz6O9xzrUHzgPuFpEz9nWivbQxB2hbj5A+4pXt7pxrClxdbVN1dfs41RYgXkRiam1rS43nfMCISDIwDLhaRLJFJBu4BBgtIi3QH+3ui1b+E415r0JDJ0/ttr+6g7h2u1vtVmb39u3remRS/3UE9ZavRr3z972b0mEjIk3Qm9udzrmCOsY33Pf5mGIvba7+rE9Cw267f9aHRaAJ+mbUu6gmmUP40QUCzrnN3t8c4CP08Wtr9aOn9zenAc6TD/wBeF5ELhCRKBEJFZGzROTxvRwSg94AdqCx4keqd4hImIhcJSKxzrkKNI7s8/adIyLp3qN8PlBVvW838tEQRXUb87ztm9GOwiy0ozAF2C4ip9SyaxeQLyJt0Hh0bbaifS97uwaZwHfAX0UkQkR6oB204/dWfj+MQeOlndEf7UloDHwTcAXaMdwSaC4i4d5NJM0L5bwKdAcGe9epCujshUw2A32BLBH5OSoK+2Jf1+N7vOsoItFem0+ptX88Gr+/Gu0IPmxEJBQVtjedcx96m+v7PjeK3/ne2uyc2+qcq3LO+dC+k+qwSoO0OdAEfR7QUUTaiUgYcDkN+Dh4rOD9yGKq3wNnop1jE6h5dL8W+KQhzuecewq4G/gd2mGXiYYAPt5L8dfRkMFmtAd/zm77xwDrvcf8m4GrvO0dgWmoyMwGXnDOTd9L/T9Q8+h9LZq9Adr2McC5QD+04ygDuMzb/39oB2s+GreuFo1q/gr8TkR2isi9eznvFejTxhb0BvpH59y0vZTbH9eibcuu/UI7hK/1wjpXo4KbjXrl53nHPg2sQ0NABainf7GIhKOfTUevbd3QG9C+qPd6eDePc9Fwykb0ZnNZrf2ZQPUK0t8cwjWog3dz+hew3Dn3dK1d9X2fJwDXeLn8A4D8WqGZgKC+Nu/WF1Dd6Q3a5su9m3w79LP+/qBPfLC9qP5+ofHZlWgH0YP+tucItbE92uO9CE15etDb3hxNcVuFimO8v209zHa+jXqKFaio3FBfG9FwwfPe5/4j+0kbPFZf9bT5Da9Ni70fdlKt8g96bV5BrbTFo2DnOODhBqprMHpzWEytdL3G/Fnvo81H9LO2of+GYdTB68RbCPRymnFhBAiBFnIxDOMIIiJ/RsMAT5iYBx7moRuGYTQSzEM3DMNoJPhtEp8WLVq4tLQ0f53eMAwjIJk/f/52V8+aon4T9LS0NDIyMvx1esMwjIBERPY20hiwkIthGEajwQTdMAyjoXEOts8FX8X+yzYgNhG+YRj+wfmgohDCYve+vzwfgsIgJNIr7yDzfSj2psePSITk8yEkai91O6ieMNJXBVVFUFUK08+CuB7Q7UGISd/zuKypsGkCJAzW43/6G1QVQ4cbIe1qWHCX/o3tCpW7oHQbbP8OwluordtmQcVOKMuF7KkQ203tjGwDPf4PmrRrkEtXH35LW+zbt6+zGLphAFVlUJEPES0bpr7iLVpfdFsIia6nzCaYdwv0+BM06w6uCoJC65bJ+kLraXtJ3e3bZkHWFDjxD1CwAsLiIG8B7FqvwrZ9NuyYAx1/BamXwc4fIaQJND0BVjyj70u3wvInVNB7PQ4pF8PW6VBZBCkXQUQrmNgZyvO0nlbDYNnjkDW5ri3BUSrMHW6AwjW6v2yb1tP6LGhzLqx6CQpXQMKpuj84QsW351+hJAsKfoJeT0BuBnx7KeDTmw3gi2pHcWU80eU/sDXyalqV7Htqm3IXjYTGEOLLI6/l7VRtnIgEhxMXsoJgV0K+L52txR1xnW6n85BRB/6Z1kJE5jvn+u51nwm6YRwmvkpwlSoU9VGxC5Y/rp5jjz/VeI8AC+6FNa/A6MUQmQyLfw/h8dDpNggO985RBRm/UpGN7wODxkPhKph7o5678x3Q9mew4G5Y/ZIKUnAkJA6FuN6QfhNEp6iAOR/8+BCseRWi24EEQfFGaDUCTh4Ha/8NW7+C7C/03K1HQ2kO9P4bxPeCiV2gOFO91Py9LJkaHAnhCVCyBaJTYdca3d70BBXPapIvBF85bPms7uWUcLYkPEJyzj0UhfchqmwBgqNKmrA95TGmr7uKqEjHSWmL2LX8Q5Ij59G0fDY+F8TKonPYUZLCsmVwcb/3iI/Koai8KeW+KOIispmx5TYWlNzFtSln0jxsNT4ngPDliovo13Yaa3I6ct1rk4kP30hsdBFTMvrSvMkO1v89jbCQCiYvGsmkRaPx+YLIK4qjrDKcGcuG0CRiF+GhZWzc3pbSigjCQsoprwz/X5tSmm/kioFv06/DPNq3XMv2xAc584aLD/w7VgsTdMPYnZKt3mNycN3tzsHSv0DufBW7rV9Cx5tVtJt0gBYD4Idfq9h1uAHyl0PmexAUAX3+DmHN1KtseTpEJMCSv2jZgp9UvEBFM/VS2PiBep5fnApF69WDjGgJmR/U2BPZBk55Bza8DategFZn6qN80kjImQmhTdWb3blIj9/2DXS8BRIGwbbvIGeGJ6ICTTupRy1BKuqJQ9UrjkqB5Atg5T9wEoL4SlV8U6+E8lzcuteo8oUivlKq4gYQtmMq5UmXE5b1Dusi7sUX3or4lDSCEvqz7IftLN/SjdQ2xZy882SC3C6+3P4YBdkbuKTr48wruJ0NpcMIDqpizvrhbMksZ2SrB/CFtSQr+AIWLIB/XXYKzWNyKSiJIfGXW0lpnknvtAVMWjSawpKme/kwHad3+ZptBQks29wNgPPOg5ytPlpGLKOgvCWhVTlc2uMZHvn8cTZkxRMRWkL3duvYnNeWP17wW2487Tl8Tnhs8UJWbO1BdDSUlkJaGvTsCf2qriep5D9sPfErvlwylOBgaNcOysth/nyIiYHTT4fgYJg1C1atgoQEuOACyMuDzExo0gTatoU2bSDkMILdJuhG4JD7gz4yJ52573IlWeoRh8XVX6YsF+b9Cpr3U2+2qgT6PKPbJ3WH1mfD4P+qt1yyFX56UgV6y2cQGgsVBRDTEQpXan2hTVVQN32sdW6freLY8VYNOWz7tubcYfEQ11NFN3EoxPVS0Vz0oIpsUJgKfGw3yF+qN4CcmXpsz4chvp+K87o3VOwBOt8FfZ6G738Jq1+kqsVQVie+RWyLprRaNBB2LmZt9B+JGfQQmZmwYQNs3w47Mjcyqv0/aRG6lJVbT6AJG+jSfAbXvLOQnl0Kmb8sia25MZzS9n1+MeB3PD39cbbIeaSm6v1t+nTYlZPJp/eeS3L8Jl779gZ+8+5jRIbkU1BSE/8W0fLVRIUX4fMFUVoRSUoKZGY6ak9R36QJtG4N3bvDTz9BdjakpsJzv3qCQZH3sdp3PUtjxhEWBlu3QrNmsHMndO0K27bBmjUwbJiKZU6Obu/SRcskJ+/5daiogNBQ/RsUpOILQPFm+DQdUq+AAeP2/l0qzYEtn0O7a+o+XfkBE3Tj6JC/DCQUmnY8uOPK87VjrHiLCm1FPoz4Fpr1gGmnq3inj4Xuf9TyZbkwsZPGSZt00PJtzoWej0BlsYYSijNViHO+AZwKKE692ahk2D5H/+/3AiScBtNOg8pCDRW0GwM9HtZOr9CmkPmRiu/sq9Wz7Xwn9H5azxOTroLtq4AtkyGqtaraV8PVrj7PQufbatpalkvxj6+yZskWWsSXkLTrZQB2nLqJ4NBQlq+MJDE5hsWLYdMmaB65mVY7HmFNxcX8lDeU7GwhIqycwR1ncOvDZ1BUrKrUp8smhnSezNOf/Bzn6iavBQWBz5t5PiICmjaFvDwf3bsHsWyZeqFt2kBVFZx2GixdqmK5YYMe17s3XHYZxMaqsG7apGJ41lkqkEVFsHAhlJTAKadA+/YqslFRKtpNm6pwb92q/wcF6bmaNKnn+1BZAvNvgxPu1rDO0WDXOohM2nfY7BjhsAVdREYBf0cXl33VOffobvvboqucNPPKPOCcm7SvOk3QGwHlebBtNrQZrUL3STsIjYHRP6oXs202NOumHuXOxSrKO76Hbr+Dog0aH86dDwvvh9M+hp+e8TIGmoOEqEivfA5aDFRvePhMaHkqzL9Tt7e7RrMMgiNg8wT1agtXqYcfEqMCffI49abD4rUjcM51ULBcO8Syv9AOu1YjYPMnMHIexHapt7m+72+FzA+oOHMpazLj2bVLRa5FCxW5yZPVIy4ogE5x39I5fhZvzL+PlSuFXr1g/XrYuFE9yB071INd83QHNue1oe/v5td73rg4rTM0FJKS9Pi8PH2cv+QS9Vbnz9ftV1+tj/spKdCjh9qXmqoCW16u2yMioLJS66udDGIEBocl6CISjM4/PgKdv3kecIVzblmtMi8DPzjn/ikiXYFJzrm0fdVrgn4MU56vceSUi7SDLrINDPzPnuUy7oCVz8KwL1UVvhym28+cA2U74OuzvdBFvgpqeS4gmnlRuUvfSxD/W3nM+WDAv6FpV/VwKwuhzXlwylswsauGQCJbaUw4/Sbo/1KNLWv/A3Ou13jwkM/Vc961to5A+3wQ5MpxOTPZXDmUqMLpxC8cAcDmyLFsbPUyZWXqQZaUwLp1KtQVFfDVV7BwoSMsuJjisnoyR4DISPVIKys1BtuqlcZa586Fli2hVy/dd++96rFGli+l0hfC+h2dKSnRkMGWLRpr7dFDhfyEEzzbg/Qyl5erXe33uv6S0djZl6AfSGi+P7DaObfWq+wddE3J2t3bDl2FHXSdyS2Hbq5xRCjfqbHftpfV5PXuTmWxhhZW/kNTypY/UbMvJl1DH03aQcdfamhlw5u6b8Hd0LSzesWuSo/buRiatIegcEi7UtPCCldpBsQ3l0DiMM0NzlsMvZ+CmRdAl3uh/XVa5/AZsPgP0OtJCInGDf4AWfE3vRG0vw463UpREUydquGBG264jsgBrfjqhx7kfdaa5cvhvfe6MHQopKfD669rnLZVqzAKCoaTnw9wBj8+1o0Tk5dy3t2/YMH6PS9JkBe96NMH7r1XiIuLprRU64yNhdxc9ZabNoXRo1W094bPp2K8pzfcbZ8fWxtvmeDgWn23YWEm5sbeORAP/RJglHPuRu//McDJzrlba5VJAqYCcUA0MNw5t8czpLd6/U0Abdu27bNhQ71TEhiHSsUuzRNOOrNGPTZNgHm/1DSyrr+B9tdqTDk4EtaOg8jW0PZSmHE25P8IBGmWQ0y6hj0WPahhiuBI7VjsfCe0PA2+uQjaX69pbqBZHwBr/gUIDJ28/87NanxVbM4KZs0aDWF06aKhhM2bYexYDVf06AGJiZpN8PLL8MMPNYdHRkJZWU2sGGDwYA1FlJRAx45e5kOOZiR07aqXJ7rgCzo0+ZLSEx6logLCwzUMERamnnXr1jWibhjHAocbcjkQQb/bq+spERmIrqV3onNub4sAAxZyOSJUlcOM0ZpqN3ymivL822HDO9rBGNkGtk4DRAU9IrEmRzimk3YiBoWDrwyGfQGthuu+/OWawZF2Ncy7GTa+p556eR6cv1EHZBT8pPnKwVH6f2SSeu0eZWUax01L06yJsDD1bGfMgOXLNYPhww81HAEa5y311ppv3hzOPltjw+vW1WRD3Hgj9Oun6WH/+peWGzpUveSgIL0pVFZqbDkurq6XaxiByuGGXA5kNeobgFEAzrnZIhIBtKABVqU/7tn0qeYYd3uwxuNe/QqUZEP339ctu+RPKuaIjoj7fqzGkbv/CbreD+U7YFIPiO+rI/UKV8IZ06FwtZaN7QaD3/NS7c6oqTe2S00suutvNJWucA0MmQhBIdBiAFvKB7Bitgru2rVD+PFH+OYb6NZNhXXqVM2aiIqC4uKaqiMjoXNn9bavvx4uvRTWrtVMi/R0FfbRo2tCD5WVWrZbN62rmt699375QkLU4zeM44ED8dBD0E7RM1Ahnwdc6ZxbWqvM58C7zrn/iEgXdOHXNm4flZuHfgD89HdYcKe+P+lRFeXS7TAhTdPkLt4BoV7uV1UZfJysg0tKs2HnEu1UHDge2l1VU2dVOQSH6fHl+RDhqd2WyRpiqTW/RXUGREWFhj+cU084qfQNiiWVJTmnsXgxZGWp911N9aCLU06BJUs0bNKunWZkLFmi6W6xsSrI/fppmMMwjAPjsDx051yliNwKTEFTEsc555aKyJ+ADOfcBOAe4BURuQvtIL1uX2Ju7Mb2uerpxvWu8cLLdsCi3+jgl5AoWPRbHdSy8T3NvwZN3Vv7H035y1sEZdt1VOO2WZrmF958z3k4gsP0b1AoRLSoSVtrPYqFC9XDjomBl16CiRPhpJNqBnGAhjKSksZQUKDC3aePxqf79tUBIu3b66CO0N2mBTEM48hzQANQvZzySbtt+0Ot98uAUxrWtEaEc5rz3PL0mrk5qtk2C6YN8eYCidL5Nkb9AKte1A7Ikx6DqDaQPU3n7ShYpumEWV9oZyUO1r+p+dvRaRr3DonW8EvamDrnq45Pv/yyDgRZtQq+/VYHeKSmwqJFNWY1bw5XXqkx7uhoePJJ2LULxoxR0a6+XVsOs2EcO9j0uUeK0m06J0dEIuDgm4sh5RKdl2PHXM0EkSBNJYxO1ZS9nJk6Z8fWrzR1MGmUDswB6PqADsCJagv9XtSslcwPdADO2nGaUtjzLziCyK4YSFy3ZwjvdAU/LFAB//hjzXuOjYX8fO1ITEyE227TDsuVK+H++zVevXUrnHOOxrfrw4TcMI49TNCPBOvG6xwilYWa6tfyNA1xZL4PK/4Gmz/VoeehMdpB2ftpHeLcbgxkfqjCXZqt04ZW0+lWFe0OP9dJnzqMhbJtVDQfTujyP+AjhI8X/ZwX74IvvggC7iAkRL3y8HC4+GL1rDdtUtG+5BITZcNobNhcLg3N1q/hyyHaOdnpFph1uW5Pv0kzQ3Z6se4eD8OJD+55/FcjNLwSngAXbq4zR3VxMUyYAG+9pZkgwcFQkbeGZY+m88H3F3HJ3z+gWTO4+27NDtm+XePbF16oIRTDMAKfw01bNPZHzjcaw47pBMse03zvoVN0RObK53XWvJRLNL/763P1mLQr915X0kjInkZh/OUUZocycya8957Gt6vn42jTRrNDKiqg8/AOLIp4hQ6XDGXJWOjQQcXcMIzjDxP0w2XnEvWqfWU1205+tWZ4fc+/aDw8cQhIsA62iUjc61JUpaUwd+0lpOb9h9H33cxyL9u/bVs4+WQNk4wapTPi1R29eOORap1hGAGECfqB4KuEda/pfNbhtWIXhath1mU69euZc6Booy511e66mjItT9VXNWd8DUEhlJbCnDk6F8iUKZpNsmoVOJdGUtISfvWrmpnyzjnHhp8bhrF/TNAPhBXPwg/3aIphz79ouuDG93VyqZAYOPV99bibtIPE0+utxjl45Y1Epk6FmTM1vxs0bXDIELjiCs3lPvdcHRpvGIZxMJig74+iDTqFbHAUrHvdW4R2B6RdpQslpP9C88T3gnOQkQHjxulc2VFRsGyZZpucdhpcc42mDvbsaXFvwzAOHxP0/bFmHPhKNaQybYhuGzkP4nrUe0hODowfr0K+dKnmc595poZXnnkGbr/dUgYNw2h4TNDro7JYB+1kfqApiM37wagMjaFH7Dnp9Zo1Ggf/8Uf45z81G+Xkk3UIffXyXYZhGEcSE3TYcxx7xS6Y0k8nvCpap6u5w16XJ9u6Ff78ZxXuykrtvLzmGl2Rptu+1y4wDMNoUEzQATJu1XnBh07WwT+LfgsFK2oG9aRcVKe4c9qp+eqr8P77mg9+001wxx06F3fcPhaiNwzDOFKYoIN2dJbm6IyFn/cCnM4h3nIw7FyqnZ/AggW6CMN//6sphrGxOof3nXdCp07+bYJhGIYJenmeLgIBsHki4GDEd5AwULclDqWqCp56Cn7zG43KDB4Mv/+9zo9Se5EFwzAMf2KCnltrYcrNEyA4Apr3/9+mmTPhl7/UdMNLLtGZCy2kYhjGsYiNP8yttZb1ju91Hc6gYN5/X2clHDJEh+S//76GWkzMDcM4VjFBz52vMXLRh5XK6C488AD87Gc6R/gDD8DixRpesdxxwzCOZY7vkEv+T5AzHRIG6yRbhSt58uWuPPamrij/wgu2lJphGIHD8euhl26HqQPAOYpS72fR2o4A7KjsyjffwCuvmJgbhhFYHH+CvuqfMH2ULvNWkY9v8EecfU1/ps9XQX/k+S4MHuxnGw3DMA6B4yvk4quAJX/WpdyqSqiSaP7wTH++/hruG3cOtFpCaFy6v600DMM4JA7IQxeRUSKyQkRWi8gD9ZS5VESWichSEXmrYc1sIDZNUDEHyJnJtEWn8MijoYweDWdddwYM+6LOkm+GYRiBxH49dBEJBp4HRgCbgHkiMsE5t6xWmY7Ab4BTnHN5IrLn7FX+xvlg+ZMQ1ZaCyiSals9lQ8lpZGTo9LWWwWIYRqBzICGX/sBq59xaABF5BzgfWFarzFjgeedcHoBzLqehDT1kdq2DuWMhvAXsmMOEnH/z7ZfbePyKuZw/9nQST/S3gYZhGA3DgQh6GyCz1v+bgJN3K9MJQERmAcHAQ865ybtXJCI3ATcBtG3b9lDsPXgW3KUdoDiWF57P+Xddyw3XFlF6UgKJXU45OjYYhmEcBRoqyyUE6AgMAa4AXhGRZrsXcs697Jzr65zrm5CQ0ECn3gfZX8GmT6DnX3hp/Tz63P4WN9wgvDyuCRFdr7M4i2EYjYoD8dA3Aym1/k/2ttVmEzDXOVcBrBORlajAz2sQKw+VVf+E8ARm5tzFzQ9GcP31OheLLbhsGEZj5ECkbR7QUUTaiUgYcDkwYbcyH6PeOSLSAg3BrG1AOw+O3B90FOjmT6lKuYxbbo8gLQ2ef97E3DCMxst+PXTnXKWI3ApMQePj45xzS0XkT0CGc26Ct+9MEVkGVAG/ds7tOJKG10veIpjqhfh9Fbw/70qWLIGPPtK1PQ3DMBor4qqXXzvK9O3b12VkZDRspVXlMLk3lO0ACaaSKJpft4JBg4RJkyxkbhhG4CMi851zffe2r3GNFN0yCfKXwuD3odVw7r61jJIS4e9/NzE3DKPx07gEfd3rEJEIyecze24Iz72i09/a8nCGYRwPNJ4uwrJc2DIRUq9g244QxoyBNm3gwQf9bZhhGMbRofF46Jkf6ORb7cZw+c9g0yaYPh2aNPG3YYZhGEeHxiXoTTqwZHMvvvoKnngCBg70t1GGYRhHj8YRcinPg+wvIeUixr8pBAfDNdf42yjDMIyjS+MQ9M0TwVXiS76YN9+EUaOg5bE336NhGMYRpXEIetYXENGSKfP6sWkTXHutvw0yDMM4+jQOQc9bAPH9eP6FIFq1gvPP97dBhmEYR5/AF/TKYihYTp70ZtIkGDsWwsL8bZRhGMbRJ/AFfedicD6mzOsDwE03+dkewzAMPxH4gp67AICX3uvN6adDcrKf7TEMw/ATgS/oeQuoDG7BjO+TufxyfxtjGIbhPwJX0H0VMP8uWPc6q/IGERwsXHyxv40yDMPwH4Ep6L5K+PYyWPEMtLuOX732MqeeCi1a+NswwzAM/xGYgp79JWz6CE56nMzWLzNjTiJnn+1vowzDMPxLYAp6rrdUafpNfP65vh092n/mGIZhHAsEqKDPh5iOEBbLpEmQmgpduvjbKMMwDP8SuIIe35eyMpg2Dc4+6eZGQQAABk5JREFU21YkMgzDCDxBL82B4kyI78PMmVBUZOEWwzAMCERBz52vf+P7MGkSRETA0KH+NckwDONY4IAEXURGicgKEVktIg/so9zFIuJEZK8rUjcI1YIe14tJk1TMo6KO2NkM4//bu7sQK+o4jOPfpy0VUirfRSUtTFCRWiS8MAmMSi+y7uymLgJvEgoKNISIujLIiyACI8EikqAioaI3Cq80t1DbTXzJjHxJdw3WbiqrXxczm8fjOeu254zjf87zgWXmzMye83v87/6Y+c85q1kyLtvQJXUBrwArgQXAw5IWNDhuAvAEsLvdRV7ktsfhnp30D97AoUOwYkWhr2ZmloyRnKHfCRyJiKMR8SewHWj0B2pfADYBv7exvkuNuQmm3kVfX/Zw8eJCX83MLBkjaegzgZ9rHh/Pt/1HUjcwOyI+HO6JJK2V1COpp7+//38XW6u3N1suWtTS05iZVUbLN0UlXQNsBp663LERsSUilkTEkilTprT0ur29MHEiTJ/e0tOYmVXGSBr6CWB2zeNZ+bYhE4BFwFeSjgFLgR2F3hgla+gLF/r952ZmQ0bS0PcA8yTNlTQGWAPsGNoZEYMRMTki5kTEHGAX8EBE9BRSMRCRNXRPt5iZXXDZhh4RfwHrgE+AA8A7EdEn6XlJDxRdYCMnT8LgoBu6mVmta0dyUER8BHxUt+3ZJsfe3XpZwzt8OFvOn1/0K5mZpSO9T4oCAwPZcurUcuswM7uaJN3QJ00qtw4zs6tJkg397Nls6YZuZnZBkg19YADGj4exY8uuxMzs6pFkQz971v9/qJlZvSQb+sCAG7qZWb1kG7rnz83MLpZkQ/eUi5nZpZJs6D5DNzO7VHIN/fx5OHfOZ+hmZvWSa+h+D7qZWWPJNfShT4n6DN3M7GLJNfShM3Q3dDOziyXX0P13XMzMGkuuofsM3cysseQaus/QzcwaS66hr1+fNfVx48quxMzs6pJcQ+/q8tm5mVkjyTV0MzNrzA3dzKwiFBHlvLDUD/w0ym+fDAy0sZwUdGJm6MzcztwZRpv55oiY0mhHaQ29FZJ6ImJJ2XVcSZ2YGToztzN3hiIye8rFzKwi3NDNzCoi1Ya+pewCStCJmaEzcztzZ2h75iTn0M3M7FKpnqGbmVkdN3Qzs4pIrqFLul/SQUlHJG0ou56iSDom6TtJeyX15NsmSvpM0uF8eVPZdbZC0lZJZyT11mxrmFGZl/Nx3y+pu7zKR69J5uckncjHeq+kVTX7nskzH5R0XzlVt0bSbElfSvpeUp+kJ/LtlR3rYTIXO9YRkcwX0AX8ANwCjAH2AQvKrqugrMeAyXXbXgQ25OsbgE1l19lixuVAN9B7uYzAKuBjQMBSYHfZ9bcx83PA0w2OXZD/jI8F5uY/+11lZxhF5hlAd74+ATiUZ6vsWA+TudCxTu0M/U7gSEQcjYg/ge3A6pJrupJWA9vy9W3AgyXW0rKI2An8Wre5WcbVwBuR2QXcKGnGlam0fZpkbmY1sD0i/oiIH4EjZL8DSYmIUxHxbb7+G3AAmEmFx3qYzM20ZaxTa+gzgZ9rHh9n+H+klAXwqaRvJK3Nt02LiFP5+i/AtHJKK1SzjFUf+3X59MLWmqm0ymWWNAe4A9hNh4x1XWYocKxTa+idZFlEdAMrgcclLa/dGdl1WqXfc9oJGXOvArcCtwOngJfKLacYksYD7wJPRsS52n1VHesGmQsd69Qa+glgds3jWfm2yomIE/nyDPA+2eXX6aFLz3x5prwKC9MsY2XHPiJOR8TfEfEP8BoXLrUrk1nSdWSN7a2IeC/fXOmxbpS56LFOraHvAeZJmitpDLAG2FFyTW0n6XpJE4bWgXuBXrKsj+aHPQp8UE6FhWqWcQfwSP4OiKXAYM3letLq5ocfIhtryDKvkTRW0lxgHvD1la6vVZIEvA4ciIjNNbsqO9bNMhc+1mXfDR7F3eNVZHeMfwA2ll1PQRlvIbvjvQ/oG8oJTAK+AA4DnwMTy661xZxvk112niebM3ysWUaydzy8ko/7d8CSsutvY+Y380z781/sGTXHb8wzHwRWll3/KDMvI5tO2Q/szb9WVXmsh8lc6Fj7o/9mZhWR2pSLmZk14YZuZlYRbuhmZhXhhm5mVhFu6GZmFeGGbmZWEW7oZmYV8S8oCEKsIJn0aQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "model.save(r'/content/drive/MyDrive/Data Project/model', save_format='h5')\n",
        "pd.DataFrame(history.history).to_csv('/content/drive/MyDrive/Data Project/model.csv')\n",
        " "
      ],
      "metadata": {
        "id": "qR4uJzKk3xcz"
      },
      "execution_count": 20,
      "outputs": []
    }
  ]
}